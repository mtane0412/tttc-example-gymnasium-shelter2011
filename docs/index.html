<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="./_next/static/css/d1386df84e9d164b.css" as="style" crossorigin=""/><link rel="stylesheet" href="./_next/static/css/d1386df84e9d164b.css" crossorigin="" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="./_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="./_next/static/chunks/webpack-1e7d36e3ced660e3.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/framework-0c7baedefba6b077.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/main-75623049b75f64cc.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/pages/_app-41fcb505e2a6ec3b.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/3e199aef-8a882f67d84a9743.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/413-fe7ad88e9897fb6d.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/664-4ccc24e47970c0fa.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/550-a21c3768867c648a.js" defer="" crossorigin=""></script><script src="./_next/static/chunks/pages/index-cc72100c2afe033d.js" defer="" crossorigin=""></script><script src="./_next/static/fW86tV8TMvqC8n4utOYdy/_buildManifest.js" defer="" crossorigin=""></script><script src="./_next/static/fW86tV8TMvqC8n4utOYdy/_ssgManifest.js" defer="" crossorigin=""></script></head><body><div id="__next"></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"result":{"clusters":[{"cluster":"読者の反応と評価","cluster_id":"1","takeaways":"参加者は、特定の記事や文章が非常に重要であり、多くの人々に読まれるべきだと強調しています。特に、日本国民全員が一度は読むべき内容であり、家族や広い範囲の人々に共有する価値があるとしています。記事の内容が具体的で率直であり、心に留めておくべき重要な情報が詰まっていると評価されています。また、定期的に読み返す価値があり、メディアで広く取り上げられるべきだとの意見も見られます。","arguments":[{"arg_id":"A1_0","argument":"これは、今から気にしないといけないことか。","comment_id":"1","x":13.501526,"y":5.828802,"p":0.8369686862906955},{"arg_id":"A7_0","argument":"読んだことを忘れているので、再度ブックマークする。","comment_id":"7","x":13.797371,"y":5.3572745,"p":1},{"arg_id":"A13_0","argument":"これは印刷して家族に読ませておきたい。","comment_id":"13","x":14.052666,"y":4.6136513,"p":0.3040182688459008},{"arg_id":"A23_0","argument":"日本国民全員に読んでほしい。","comment_id":"23","x":13.792755,"y":4.2720833,"p":0.7219342521604115},{"arg_id":"A32_0","argument":"心に留め、皆に伝えるべき記事だ。","comment_id":"32","x":13.361351,"y":4.7448673,"p":0.320108495929214},{"arg_id":"A47_0","argument":"多くの人に読んでほしい内容。","comment_id":"47","x":13.4782915,"y":4.4997354,"p":0.3530797193370115},{"arg_id":"A49_2","argument":"決まったことの説明は全員が揃った時に行う。","comment_id":"49","x":13.735569,"y":4.193639,"p":0.4852504538654125},{"arg_id":"A51_0","argument":"必読。明日のわが身。","comment_id":"51","x":14.052222,"y":4.829025,"p":0.4913144019161607},{"arg_id":"A54_0","argument":"広く読まれてほしい。","comment_id":"54","x":13.836229,"y":4.5343084,"p":0.3695574552998349},{"arg_id":"A57_0","argument":"詳細なまとめを作成し、多くの人と共有するべきである。","comment_id":"57","x":12.5810585,"y":5.47868,"p":0.7702946771553949},{"arg_id":"A84_0","argument":"これは読むべきだ。","comment_id":"84","x":14.085938,"y":4.9846125,"p":0.7045023732724837},{"arg_id":"A92_0","argument":"具体的で率直、覚えておきたい大事なことが詰まった記事。","comment_id":"92","x":13.044614,"y":5.474257,"p":0.7344269846210795},{"arg_id":"A98_0","argument":"よく読む。","comment_id":"98","x":13.661863,"y":4.76169,"p":0},{"arg_id":"A100_0","argument":"ドラマより感動的で泣ける。","comment_id":"100","x":12.751019,"y":4.3636312,"p":0},{"arg_id":"A101_0","argument":"これは後でじっくりと読みたい。","comment_id":"101","x":14.044472,"y":4.9521675,"p":1},{"arg_id":"A102_0","argument":"こういうのを一つ読むだけでも心構えが変わると思う。","comment_id":"102","x":13.636796,"y":5.338852,"p":1},{"arg_id":"A102_1","argument":"できるだけ多くの人に読んでもらいたい。","comment_id":"102","x":13.607899,"y":4.392881,"p":0.6412850177852034},{"arg_id":"A112_0","argument":"素晴らしい記事。もっと多くの人に見てもらえるよう、テレビなどの大手メディアで取り上げてもらいたい。","comment_id":"112","x":12.638979,"y":4.9796195,"p":1},{"arg_id":"A118_0","argument":"これは定期的に読むべき記事だ。","comment_id":"118","x":13.605923,"y":5.3575993,"p":0.8575810381543411},{"arg_id":"A119_0","argument":"興味深い記事。次回があっては困るけど、何かあった時に必ず役立つ。覚えておきたい。","comment_id":"119","x":12.962395,"y":5.4948406,"p":0.8151071998935063},{"arg_id":"A120_0","argument":"いつ来るか分からないので、しっかり読んでおきます。","comment_id":"120","x":13.8963175,"y":4.9319305,"p":0.9243856009284798},{"arg_id":"A124_0","argument":"公平、公正、持続性についての記事だった。","comment_id":"124","x":12.78542,"y":5.3535805,"p":1},{"arg_id":"A127_0","argument":"みんなに読んでほしい記事。","comment_id":"127","x":13.671224,"y":4.3628554,"p":1},{"arg_id":"A133_0","argument":"前半が感動的すぎて泣ける。","comment_id":"133","x":12.634036,"y":4.3621807,"p":0},{"arg_id":"A134_0","argument":"これは全ての世代の人々が一度読んでおくべき記事である。","comment_id":"134","x":13.675655,"y":4.478626,"p":0.6049161233401176},{"arg_id":"A139_0","argument":"ここ最近読んだ中で最も貴重な文章だったと思う。","comment_id":"139","x":13.273291,"y":5.137045,"p":0},{"arg_id":"A139_1","argument":"こういう記事こそもっと広めて共有すべきだ。","comment_id":"139","x":12.617486,"y":5.1530356,"p":1},{"arg_id":"A150_0","argument":"あとでしっかり読む。","comment_id":"150","x":13.955246,"y":4.9518723,"p":0.9744456907463884},{"arg_id":"A155_0","argument":"必読。何度も読み返しておきたい。","comment_id":"155","x":13.7413645,"y":5.0286527,"p":1},{"arg_id":"A158_0","argument":"文章では簡単に見えるが、実際には多くのストレスがあっただろう。","comment_id":"158","x":13.261556,"y":5.7137027,"p":1},{"arg_id":"A161_0","argument":"みんな読んだほうがいい。","comment_id":"161","x":13.753614,"y":4.3636103,"p":0.850576877065198},{"arg_id":"A162_0","argument":"ときどき読み返したい。","comment_id":"162","x":13.693439,"y":5.0969605,"p":1},{"arg_id":"A170_0","argument":"淡々と書かれているのが逆に涙が出る。","comment_id":"170","x":13.109625,"y":4.926479,"p":0},{"arg_id":"A174_0","argument":"一度は読んでおくべき文章である。","comment_id":"174","x":13.837279,"y":4.9033775,"p":0.8967175632953304},{"arg_id":"A175_0","argument":"新聞に掲載されることで、多くの人が読んで幸せになるのではないか。","comment_id":"175","x":13.273831,"y":4.482284,"p":0.3415274102531709},{"arg_id":"A175_1","argument":"意識付けのためにも、新聞に掲載するべきだ。","comment_id":"175","x":13.37108,"y":4.8623424,"p":0},{"arg_id":"A179_0","argument":"ぜひ読むべき。","comment_id":"179","x":14.014083,"y":4.9372716,"p":1},{"arg_id":"A187_0","argument":"日本に住むすべての人が一度は読んでおくべき内容。","comment_id":"187","x":13.73163,"y":4.338011,"p":1},{"arg_id":"A190_0","argument":"風化しないためにブックマーク。","comment_id":"190","x":13.897976,"y":5.454252,"p":0},{"arg_id":"A192_0","argument":"途中で内容が難しく、一気に読むことができなかった。","comment_id":"192","x":13.762827,"y":5.0146184,"p":1},{"arg_id":"A198_1","argument":"テキストはとても整理されていて示唆に富んでおり、良い内容です。","comment_id":"198","x":12.786536,"y":4.708044,"p":0},{"arg_id":"A199_0","argument":"必読","comment_id":"199","x":13.676747,"y":4.879796,"p":0.4825138675353811},{"arg_id":"A213_0","argument":"細かく、深い良記事。","comment_id":"213","x":12.823348,"y":5.115222,"p":1},{"arg_id":"A215_0","argument":"これは読んでおいた方がいい。次にどこかで発生した時に必ず役に立つ。","comment_id":"215","x":14.027991,"y":5.17981,"p":0},{"arg_id":"A221_0","argument":"本当に忘れてはいけないことだと思う。何度も読んで心に刻んでおきたい。","comment_id":"221","x":13.755456,"y":5.258609,"p":1},{"arg_id":"A230_0","argument":"これはぜひ読むべき。すばらしいエントリーだった。","comment_id":"230","x":12.832991,"y":4.871607,"p":0.8312070843342476},{"arg_id":"A231_0","argument":"良いエントリだ。特に平等を心掛けている点が良い。人は目の前の苦境よりも不公平さに腹が立つものだから。分かっていても「何であいつらだけ」という思いは中々拭えない。","comment_id":"231","x":12.523753,"y":5.00722,"p":1},{"arg_id":"A238_0","argument":"必読。","comment_id":"238","x":13.856145,"y":4.835662,"p":0.8623931362224341},{"arg_id":"A246_1","argument":"この記事も同様に貴重である。","comment_id":"246","x":12.895821,"y":5.271725,"p":1},{"arg_id":"A253_0","argument":"良い記事だと思う。葉物野菜が不足していたという点に共感する。","comment_id":"253","x":12.7979965,"y":5.1915402,"p":1},{"arg_id":"A257_0","argument":"時々読み返して万が一の時に備えたい、ぜひ読んでおきたい名記事。","comment_id":"257","x":13.492039,"y":5.235408,"p":0},{"arg_id":"A261_0","argument":"読者を引き込む魅力的な文章","comment_id":"261","x":13.197579,"y":4.599571,"p":0.320108495929214},{"arg_id":"A263_0","argument":"読む価値があった。","comment_id":"263","x":13.7983265,"y":4.848124,"p":0.8967175632953304},{"arg_id":"A264_0","argument":"一ページ目も胸に迫るが、二ページ目もまた感動的である。","comment_id":"264","x":12.983417,"y":4.50921,"p":0}]},{"cluster":"貴重な教訓の共有","cluster_id":"4","takeaways":"この記事は、実務的な経験談を通じて現場での共通意識を形成する重要性を強調しています。多くの人々がこの貴重な体験記を読むことで、知見を共有し、次に繋がる情報を得ることができるとされています。特に、マニュアルとしても通用する内容であり、後世に残すべき知恵として評価されています。経験に基づく実践的なノウハウが凝縮されており、教育やマネジメントにおいても非常に有用であるとされています。この記事を広く共有し、記録として残すことの重要性が強調されています。","arguments":[{"arg_id":"A2_0","argument":"この内容は数年前にツイッターで読んだが、今も教訓として色あせない。語り継がれて欲しい。","comment_id":"2","x":13.048883,"y":5.7892017,"p":1},{"arg_id":"A4_0","argument":"1年前の記事だが、貴重で実務的な経験談を多くの人が読むことで、現場での共通意識が作りやすくなる。広まって欲しい。","comment_id":"4","x":12.65506,"y":6.1794925,"p":1},{"arg_id":"A11_0","argument":"これはマニュアルとしても通用する永久保存版だと思う。","comment_id":"11","x":13.254681,"y":6.526253,"p":0},{"arg_id":"A12_0","argument":"非常に参考になる体験記。","comment_id":"12","x":12.843854,"y":6.931234,"p":1},{"arg_id":"A18_0","argument":"記録してくれてありがとう。","comment_id":"18","x":13.3946905,"y":6.934185,"p":1},{"arg_id":"A19_1","argument":"それがなければこういう記録もなかったかもと考えると鳥肌が立ちます。","comment_id":"19","x":12.762661,"y":7.467603,"p":0},{"arg_id":"A21_1","argument":"定期的にこういう話題が上がってくるのは平和ボケしまくりの私には本当に助かる。","comment_id":"21","x":12.52396,"y":6.2395735,"p":0},{"arg_id":"A25_0","argument":"次世代に継承していきたい知見。","comment_id":"25","x":12.834583,"y":6.21452,"p":1},{"arg_id":"A33_0","argument":"とても重要な知見。こういう話こそ教科書にすべきだ。","comment_id":"33","x":12.87656,"y":6.7171874,"p":1},{"arg_id":"A40_1","argument":"こういう貴重な記録は定期的に読み返したい。","comment_id":"40","x":13.54294,"y":6.178521,"p":0},{"arg_id":"A64_0","argument":"貴重なノウハウや体験の共有は重要である。","comment_id":"64","x":12.569116,"y":6.99872,"p":1},{"arg_id":"A65_0","argument":"ローカルに保存。","comment_id":"65","x":13.384393,"y":6.781656,"p":0.8415863489856258},{"arg_id":"A66_1","argument":"本当に貴重な体験を書いてくれたことに感謝いたします。","comment_id":"66","x":13.1069975,"y":7.0164437,"p":0.7250037411323281},{"arg_id":"A74_0","argument":"自分は何も理解できていないかもしれないが、こういう情報はありがたい。","comment_id":"74","x":12.303403,"y":6.5886545,"p":0},{"arg_id":"A75_0","argument":"こういういろんなことに気がつける人っているんだな…","comment_id":"75","x":11.796625,"y":7.1690264,"p":0},{"arg_id":"A80_0","argument":"こういう体験を“口伝”ではなく、誰もが読める一次資料として公開するのは本当に大事である。","comment_id":"80","x":12.69088,"y":6.570521,"p":1},{"arg_id":"A82_1","argument":"役に立つ反省や次に繋がる情報をみんなが欲しがっている。","comment_id":"82","x":12.022454,"y":6.525327,"p":0.974957579986036},{"arg_id":"A83_0","argument":"この貴重な教訓を自分のものにし、お亡くなりになった方々のご冥福をお祈り申し上げます。","comment_id":"83","x":12.837242,"y":6.887397,"p":1},{"arg_id":"A86_2","argument":"この情報が本当に貴重だ。","comment_id":"86","x":13.04303,"y":6.506619,"p":1},{"arg_id":"A94_0","argument":"貴重かつ重要な記録です。","comment_id":"94","x":13.313373,"y":6.8106675,"p":0.9484642428896312},{"arg_id":"A97_0","argument":"こういうものを記録に残してくれるのは、とてもありがたい。","comment_id":"97","x":13.266083,"y":6.937807,"p":1},{"arg_id":"A103_0","argument":"たくさんの命と引き換えに得た貴重な知恵を失わないようにしなければならない。","comment_id":"103","x":12.50888,"y":6.9240727,"p":1},{"arg_id":"A104_0","argument":"記録に残してくれてありがとう。","comment_id":"104","x":13.483717,"y":6.993769,"p":0.6193596317550373},{"arg_id":"A109_0","argument":"これは必読である。こういう体験談やノウハウはもっと広く知られるべきである。","comment_id":"109","x":12.984289,"y":6.3169785,"p":1},{"arg_id":"A122_0","argument":"貴重な経験則を残していただきありがとうございます。しっかりEvernoteに記録します。","comment_id":"122","x":13.280674,"y":7.037641,"p":0.8356769124957244},{"arg_id":"A126_0","argument":"体験談としても資料としてもとても良い。","comment_id":"126","x":12.594704,"y":6.803057,"p":0.5833875032684177},{"arg_id":"A126_1","argument":"体験しないとわからないノウハウはとても貴重である。","comment_id":"126","x":12.767055,"y":7.1544847,"p":0.9171486961326448},{"arg_id":"A132_0","argument":"必読。後世に残すべき知恵。","comment_id":"132","x":13.1245165,"y":6.0409927,"p":0.8829506194707184},{"arg_id":"A136_0","argument":"実際に体験しないと分からないことが多いので、こうして記録を残してくれるのは非常に有り難い。","comment_id":"136","x":13.04269,"y":7.293208,"p":0},{"arg_id":"A141_0","argument":"マネジメントに関する有用な知見が凝縮されている。","comment_id":"141","x":12.0887785,"y":6.8698063,"p":0},{"arg_id":"A167_0","argument":"こういう体験談は散逸しないうちに誰かがまとめてアニュアル化し、後世に役立ててほしい。","comment_id":"167","x":12.782545,"y":6.4134536,"p":1},{"arg_id":"A171_0","argument":"実践的なノウハウが蓄積されている良記事。いつか必要になる日が来るかもしれないので読んでおくべき。","comment_id":"171","x":12.821495,"y":5.7978153,"p":0},{"arg_id":"A174_1","argument":"経験された方は多いが、これだけの文章になることはあまりない。","comment_id":"174","x":12.976016,"y":6.332816,"p":1},{"arg_id":"A197_0","argument":"海の上でも揺れるのか…。これは驚き。しかしケータイ無かった時代はどうなってたんだろうと思うと…。","comment_id":"197","x":12.096239,"y":8.237204,"p":0},{"arg_id":"A200_0","argument":"場所とそのコミュニティの違い、季節の違いを考慮する必要があるが、とても貴重な知見である。","comment_id":"200","x":12.261833,"y":7.2598605,"p":0},{"arg_id":"A209_0","argument":"経験は何物にも勝る知恵である。","comment_id":"209","x":12.5922,"y":7.003509,"p":1},{"arg_id":"A214_0","argument":"色々な方の見解や経験を広く知っておくことは重要である。","comment_id":"214","x":12.2672825,"y":7.018996,"p":0.4948396713874419},{"arg_id":"A216_0","argument":"善意の押し付けにならないために、情報共有の在り方は重要である。","comment_id":"216","x":12.203987,"y":6.6210995,"p":1},{"arg_id":"A217_0","argument":"リアルで後世に役立つ貴重な知識。","comment_id":"217","x":12.775166,"y":6.4183207,"p":1},{"arg_id":"A242_0","argument":"道徳よりも、実例を多く見聞することが教育には向いていると思う。","comment_id":"242","x":12.31016,"y":7.020718,"p":0.5209606862921529},{"arg_id":"A243_2","argument":"資産や思い出の写真の電子化やクラウド化が役に立つかもしれない。","comment_id":"243","x":12.029541,"y":6.523061,"p":1},{"arg_id":"A245_0","argument":"これは過去のことではなく、現在も続いていること。","comment_id":"245","x":13.249944,"y":5.9455442,"p":1},{"arg_id":"A246_0","argument":"希少事例の経験は本当に貴重である。阪神・中越経験者の「ありがたかった支援と困った支援」のくだりがその例である。","comment_id":"246","x":12.448573,"y":7.215839,"p":0},{"arg_id":"A247_0","argument":"読んで震えた…生死を分けるのは本当に一瞬の判断なんだな…","comment_id":"247","x":12.2413645,"y":8.241939,"p":0},{"arg_id":"A248_0","argument":"こういう事をしたとか、こういう事が起きたとか、こういう事はありがたかったとか迷惑だったとか、そういった内容は小学校で広く教えてほしい。","comment_id":"248","x":12.57465,"y":6.4875383,"p":0.9693612707687512}]},{"cluster":"防災対策","cluster_id":"2","takeaways":"震災に関心がある人々は、過去の震災経験や避難所運営の実際の行動と考え方を学ぶことが重要であると強調されています。特に、阪神淡路大震災の知見が現在の防災対策に生かされている点や、南海トラフ地震への備えが必要であることが指摘されています。また、防災士の役割や資格の重要性、地域コミュニティの防災対策の必要性についても議論されています。体験者の言葉や具体的なアドバイスが防災に役立つとされ、情報共有の重要性も強調されています。","arguments":[{"arg_id":"A3_0","argument":"防災","comment_id":"3","x":10.611519,"y":10.195096,"p":1},{"arg_id":"A8_0","argument":"震災に関心がある人は、一度これを読んでみると良いと思う。","comment_id":"8","x":11.281132,"y":11.109711,"p":1},{"arg_id":"A9_0","argument":"地震が起きて「何か力になりたい」と思う人は読むべき内容です。すべての善意がいい方向に働くわけではない。","comment_id":"9","x":11.399389,"y":11.1086855,"p":1},{"arg_id":"A10_0","argument":"地震が起きて「何か力になりたい」と思う人は読むべき内容です。すべての善意がいい方向に働くわけではない。","comment_id":"10","x":11.382781,"y":11.111862,"p":1},{"arg_id":"A31_0","argument":"大きな地震の後、避難所運営についての話。","comment_id":"31","x":10.628559,"y":10.780663,"p":1},{"arg_id":"A34_0","argument":"防災","comment_id":"34","x":10.711243,"y":10.364995,"p":0.4412411125915523},{"arg_id":"A36_0","argument":"阪神淡路大震災の頃と比べると改善されており、当時の知見が生かされていると感じる。","comment_id":"36","x":10.692329,"y":11.130057,"p":1},{"arg_id":"A40_0","argument":"私たちは被災者にも支援者にもなり得る。","comment_id":"40","x":10.58788,"y":9.917119,"p":0},{"arg_id":"A44_0","argument":"隣で起きた災害のレベルについて。救急隊や避難情報の話はよく聞いていた。","comment_id":"44","x":10.349729,"y":10.622186,"p":1},{"arg_id":"A50_0","argument":"地震の影響で再び湧き出た町内会で塞いだ湧き水が近くにあり、非常に助かった。","comment_id":"50","x":10.770792,"y":11.065846,"p":0.8709858102151579},{"arg_id":"A55_0","argument":"防災に関する参考資料を提供する。","comment_id":"55","x":10.5832405,"y":10.263774,"p":1},{"arg_id":"A71_1","argument":"大規模災害に備えるための貴重な情報と意見が含まれている。","comment_id":"71","x":10.787888,"y":10.290797,"p":0.4795215644778749},{"arg_id":"A84_1","argument":"災害は怖い。","comment_id":"84","x":11.060029,"y":10.251064,"p":1},{"arg_id":"A93_0","argument":"いつか起こる南海トラフ地震に備えるべきである。","comment_id":"93","x":11.414769,"y":10.457956,"p":0},{"arg_id":"A95_0","argument":"震災発生から避難所運営までの実際の行動と考え方を明確に記録する。","comment_id":"95","x":10.524647,"y":10.589035,"p":0.9554708836483184},{"arg_id":"A96_0","argument":"素晴らしい。これをブックマークしている皆さんには、もしよければ『神戸在住』の第3巻も読んでほしい。阪神大震災の当時の話が載っている。","comment_id":"96","x":10.507016,"y":11.172274,"p":0.5782160366721121},{"arg_id":"A111_0","argument":"災害時の教科書！","comment_id":"111","x":10.947775,"y":10.284519,"p":1},{"arg_id":"A143_1","argument":"これらのアイデアは、この人が防災士であることから思いついたのだろうか？","comment_id":"143","x":10.509772,"y":9.580396,"p":1},{"arg_id":"A151_1","argument":"近い将来関東で震災が起きた場合の想定について、もっと議論と考察が必要である。","comment_id":"151","x":11.1149435,"y":10.288707,"p":0.7245859709064635},{"arg_id":"A156_0","argument":"被災者の冷静な体験談を聞くことが防災に最も役立つ。","comment_id":"156","x":10.758383,"y":10.697106,"p":1},{"arg_id":"A164_0","argument":"防災関連のブログポストも書きたい。","comment_id":"164","x":10.4129925,"y":10.51484,"p":1},{"arg_id":"A166_0","argument":"都内では津波より火炎旋風の方が心配だ。","comment_id":"166","x":11.1487465,"y":10.398278,"p":0.4454040592132715},{"arg_id":"A166_1","argument":"昨年から地区の防災対策特別委員をしているが、地域に数万人いるのに町内会がないところが多く、対策が不安だ。","comment_id":"166","x":10.617914,"y":9.199707,"p":0},{"arg_id":"A168_2","argument":"観天望気の知識を身につけ、家具を固定し、常に災害警報の情報に気を配ることが重要である。","comment_id":"168","x":11.016875,"y":10.304765,"p":1},{"arg_id":"A173_0","argument":"ものすごい手際の良さだと思ったら「防災士」。町内会に一人は欲しい人材。","comment_id":"173","x":10.404198,"y":9.502293,"p":1},{"arg_id":"A178_0","argument":"東京が被災した場合、煩い子供を隔離せよとの声が上がるだろう。","comment_id":"178","x":11.128697,"y":10.156335,"p":0.5410484358818823},{"arg_id":"A182_0","argument":"小学校の「生活科」に適した案件に見える。","comment_id":"182","x":11.382658,"y":9.964954,"p":0},{"arg_id":"A183_1","argument":"手記と災害マニュアル的な内容が混在しているため、別立てにするともっと活用範囲が広がるのではないか。","comment_id":"183","x":10.568861,"y":10.148171,"p":1},{"arg_id":"A184_1","argument":"震災にあった時や支援する側に立った時のためにも読んでよかった。","comment_id":"184","x":11.043838,"y":11.111786,"p":1},{"arg_id":"A189_1","argument":"阪神大震災を経験した人たちの的確な対応がすごい。","comment_id":"189","x":10.666793,"y":11.223249,"p":1},{"arg_id":"A194_0","argument":"地震発生の瞬間から避難所生活まで、当事者の語る言葉の臨場感とその内容のリアルさは凄い。","comment_id":"194","x":10.999885,"y":10.990394,"p":1},{"arg_id":"A197_1","argument":"防災士って初めて知った。NPOがやってる資格か。なるほど。","comment_id":"197","x":10.442816,"y":9.6480255,"p":1},{"arg_id":"A206_0","argument":"震災記録","comment_id":"206","x":10.645291,"y":10.742107,"p":1},{"arg_id":"A209_1","argument":"阪神淡路大震災や中越地震の経験者から贅沢と思えるような物も届き、嬉しかった。","comment_id":"209","x":10.772157,"y":11.192014,"p":1},{"arg_id":"A210_0","argument":"地震が起きた時は逃げる選択肢を捨てないでください。","comment_id":"210","x":11.246307,"y":10.9484005,"p":0.7166244846046462},{"arg_id":"A216_1","argument":"情報共有の在り方は、被災時に限らずどんな組織にも重要な話である。","comment_id":"216","x":10.63507,"y":9.999343,"p":0.7151607550632864},{"arg_id":"A219_0","argument":"災害によって社会基盤が破壊されると、各々のサバイバビリティが重要になる。","comment_id":"219","x":11.019672,"y":9.824169,"p":1},{"arg_id":"A219_1","argument":"究極的には自主防災ができるかどうかが鍵であり、必要なのは原始の共同体である。","comment_id":"219","x":10.975705,"y":9.519126,"p":0.6172014179543485},{"arg_id":"A222_1","argument":"防災士の国家資格化が急務である。","comment_id":"222","x":10.582095,"y":9.708625,"p":0.9925693564861876},{"arg_id":"A224_0","argument":"町会や学校で防災訓練は行われているが、発生時の一時的な訓練に過ぎない。","comment_id":"224","x":10.798838,"y":9.71966,"p":0.8362275473561908},{"arg_id":"A224_1","argument":"町会で災害時のマネジメント担当を考えるべきだ。","comment_id":"224","x":10.726992,"y":9.62444,"p":0.8996629551944255},{"arg_id":"A229_0","argument":"前震災経験者の話を聞くだけで泣けてくる。戦争経験者の識も本当に尊い。","comment_id":"229","x":11.013897,"y":11.020703,"p":1},{"arg_id":"A230_1","argument":"災害時の「その後」の知見が詰まっている。","comment_id":"230","x":10.925736,"y":10.432413,"p":0.4590845712930217},{"arg_id":"A239_0","argument":"地震国に住んでいる以上、被災地以外の人々も体験談から学ぶべきである。","comment_id":"239","x":11.132438,"y":10.832924,"p":0.5745541966707286},{"arg_id":"A243_1","argument":"災害時は大事なものを取りに戻らず、まず命を守ることが重要だ。","comment_id":"243","x":11.076724,"y":9.931332,"p":1},{"arg_id":"A251_0","argument":"小中学校の空調整備は、災害発生時の避難先としての有用性を向上させるために考慮すべきである。","comment_id":"251","x":11.292229,"y":10.046388,"p":0},{"arg_id":"A254_0","argument":"体験者の言葉は重要だ。3.11直後に阪神淡路大震災で避難所の運営にあたった方の話をラジオで聞いた。","comment_id":"254","x":10.57837,"y":10.93833,"p":0},{"arg_id":"A254_1","argument":"災害から2年後のことまで考えて燃え尽きないようにしてくださいというアドバイスが印象に残っている。","comment_id":"254","x":10.934573,"y":10.25868,"p":0.7633645189071825},{"arg_id":"A256_0","argument":"災害時には自己解決力が重要である。","comment_id":"256","x":11.091629,"y":9.803874,"p":1},{"arg_id":"A256_1","argument":"自衛隊や救助隊に頼るだけではなく、自分たちで防災の準備をすることが大切である。","comment_id":"256","x":10.963783,"y":9.646878,"p":0.6081979020011481},{"arg_id":"A258_0","argument":"減災は、行政・地域・個人のすべての単位で取り組むことで効果を発揮する。","comment_id":"258","x":11.011021,"y":9.613564,"p":1},{"arg_id":"A262_1","argument":"減災は、だれが取り組むのか。","comment_id":"262","x":11.002047,"y":9.551985,"p":1}]},{"cluster":"避難所運営と体験談","cluster_id":"3","takeaways":"東日本大震災における避難所運営の経験を共有する佐藤一男氏の寄稿は、避難所生活の実態と運営の課題を具体的に描写しています。岩手県陸前高田市米崎小学校の体育館で二ヶ月間避難所生活を送りながら、避難所運営に携わった経験から、避難所での秩序維持の難しさや、物資配布の混乱、支援活動の工夫と課題が詳細に報告されています。特に、避難者への配慮やコミュニティの関わり方、ボランティア活動の注意点など、今後の防災対策に役立つ貴重な教訓が多く含まれています。","arguments":[{"arg_id":"A5_0","argument":"東日本大震災では、東日本全体で21,000人もの人が命を失い、または行方不明となりました。私も被災し、岩手県陸前高田市米崎小学校の体育館で二ヶ月間避難所生活をしながら避難所運営を経験しました。","comment_id":"5","x":9.985458,"y":11.556858,"p":0.0797292891925448},{"arg_id":"A15_0","argument":"都市の籠城戦に近い経験をされたのだと思う。","comment_id":"15","x":9.635237,"y":10.599957,"p":0.689122720445273},{"arg_id":"A17_0","argument":"大船渡の寿司屋さんがかっこよすぎる。被災3日目、自身も被災した中でネタがだめになるから「握って配ってしまおう」とシャリの仕込みを始めたそうです。","comment_id":"17","x":10.305039,"y":11.060732,"p":0},{"arg_id":"A24_0","argument":"2015年6月25日のエントリ: 陸前高田市米崎小学校の体育館で二ヶ月間避難所生活をしながら避難所運営をした方の寄稿。","comment_id":"24","x":9.61591,"y":11.1757345,"p":1},{"arg_id":"A28_0","argument":"東日本大震災の体育館避難所では、階段を上がる際に手を貸す必要のある方がいました。","comment_id":"28","x":9.878447,"y":11.709708,"p":0.1515442706729175},{"arg_id":"A37_0","argument":"避難所運営や炊き出し支援など、共有されるべき教訓が多い。","comment_id":"37","x":9.86016,"y":10.216552,"p":1},{"arg_id":"A38_0","argument":"私は被災し、岩手県陸前高田市米崎小学校の体育館で二ヶ月間避難所生活をしながら避難所運営を経験しました。","comment_id":"38","x":9.722173,"y":11.264905,"p":1},{"arg_id":"A39_0","argument":"コミュニティへの関わり方全般で役に立つ知見だと感じた。もちろん避難所ではもっと役に立つだろう。","comment_id":"39","x":10.051841,"y":10.015843,"p":0},{"arg_id":"A39_1","argument":"東日本大震災、体育館避難所で起きたこと / 佐藤一男 / 防災士 | SYNODOS -シノドス-","comment_id":"39","x":9.840054,"y":12.007751,"p":0.466718521018192},{"arg_id":"A41_0","argument":"避難所運営で大変だったことや心がけたこと、被災経験者の支援、管理なき「配布会」の問題などがある。","comment_id":"41","x":9.814705,"y":9.823876,"p":1},{"arg_id":"A43_0","argument":"避難所運営で心がけたこと","comment_id":"43","x":9.497133,"y":10.136962,"p":0.4392488555167104},{"arg_id":"A52_0","argument":"3月15日過ぎはプレスカブに物資を積んで走り回っていた。空いた荷台に座布団を敷いて乗ってもらったおばあさんから昨年手紙が届いた。わんちゃんと共に元気とのこと。無事に過ごしてほしい。","comment_id":"52","x":9.515062,"y":11.124814,"p":0},{"arg_id":"A53_0","argument":"新聞やテレビでは「被災地では皆、混乱の中、整然としていました」と報道されていましたが、管理者のいる所では整然としていました。しかし、管理者のいない所では一度混乱が起きると整然とするのには大変な手間と時間が必要でした。","comment_id":"53","x":10.070575,"y":9.65837,"p":0},{"arg_id":"A56_0","argument":"混乱と混沌の中で秩序を保つのは難しい。","comment_id":"56","x":9.895233,"y":9.582245,"p":0},{"arg_id":"A58_0","argument":"自治組織の立ち上がりから初期の避難所の様子を読みふけった。","comment_id":"58","x":9.744407,"y":9.996748,"p":0.9114330289119942},{"arg_id":"A58_1","argument":"まったく別の場所だったけど経験を思い出す。","comment_id":"58","x":9.40451,"y":10.710959,"p":1},{"arg_id":"A71_0","argument":"避難所の体験談、運営の改善点、被災者への支援で気になった点が書かれている。","comment_id":"71","x":10.077097,"y":10.494409,"p":0},{"arg_id":"A72_0","argument":"【SYNODOS】東日本大震災、体育館避難所で起きたこと／佐藤一男 / 防災士","comment_id":"72","x":9.831564,"y":11.935037,"p":0.5155367285383675},{"arg_id":"A74_1","argument":"東日本大震災、体育館避難所で起きたこと / 佐藤一男 / 防災士 | SYNODOS -シノドス-","comment_id":"74","x":9.806406,"y":11.989156,"p":1},{"arg_id":"A77_0","argument":"戦後の混乱時には、瀬戸内寂聴が言っていたように、並んで待つより奪うことが正しかったのかもしれない。","comment_id":"77","x":9.707557,"y":9.748533,"p":0.970152748574494},{"arg_id":"A85_0","argument":"避難所経営の1事例。書いてくださってありがとうございました。","comment_id":"85","x":9.492774,"y":10.315722,"p":0.3063695223718521},{"arg_id":"A105_0","argument":"避難所生活で行われた配慮や工夫、困ったことや助かったこと、困った支援などについての貴重なレポート。","comment_id":"105","x":9.944799,"y":10.38368,"p":1},{"arg_id":"A110_0","argument":"岩手の津波と消防団、被災時の状況とその後の避難所生活をまとめた記事。","comment_id":"110","x":10.20943,"y":10.718371,"p":1},{"arg_id":"A121_0","argument":"避難所での組織とルール作りは見事である。","comment_id":"121","x":9.499574,"y":9.938729,"p":0},{"arg_id":"A125_0","argument":"良記事。震災時の避難所で、これだけの運営ができるのかと感心した。","comment_id":"125","x":10.12591,"y":10.860596,"p":0.939947139849401},{"arg_id":"A135_0","argument":"避難所運営で良かった事、悪かった事。","comment_id":"135","x":9.609179,"y":10.121133,"p":1},{"arg_id":"A146_0","argument":"難民キャンプの運営","comment_id":"146","x":9.552871,"y":10.165027,"p":0.7964910491480923},{"arg_id":"A160_0","argument":"【SYNODOS】東日本大震災、体育館避難所で起きたこと／佐藤一男 / 防災士","comment_id":"160","x":9.789815,"y":11.972052,"p":1},{"arg_id":"A183_0","argument":"陸前高田市で消防団員だった方の寄稿文は貴重な記録である。","comment_id":"183","x":9.40474,"y":10.573485,"p":1},{"arg_id":"A186_0","argument":"避難所の運営に関するノウハウ。","comment_id":"186","x":9.626516,"y":10.161105,"p":1},{"arg_id":"A198_0","argument":"タイトルに違和感があります。継続的に読み継がれて欲しいので、「避難所運営のノウハウ」などが読み取れる方が良いと思います。","comment_id":"198","x":9.612177,"y":10.170747,"p":1},{"arg_id":"A201_0","argument":"避難生活の大変さやボランティア活動の注意点など、非常に有用な情報が含まれている。","comment_id":"201","x":9.892583,"y":10.191999,"p":0.9429839980913608},{"arg_id":"A204_0","argument":"避難所運営の優れたエントリ。","comment_id":"204","x":9.596836,"y":10.300963,"p":0.3790844813503958},{"arg_id":"A218_0","argument":"新聞やテレビでは「被災地では皆、混乱の中、整然としていました」と報道されていましたが、管理者のいる所では整然としていたものの、そうでない所では一度混乱が起きると整然とするのには大変な手間と時間がかかりました。","comment_id":"218","x":9.882848,"y":9.7518835,"p":1},{"arg_id":"A233_0","argument":"『米崎小学校の体育館で二ヶ月間にわたり避難所生活をしながら避難所運営を経験』具体的で素晴らしい。必読。","comment_id":"233","x":9.78068,"y":11.048663,"p":1},{"arg_id":"A237_0","argument":"【SYNODOS】東日本大震災、体育館避難所で起きたこと／佐藤一男 / 防災士","comment_id":"237","x":9.777706,"y":11.98723,"p":1},{"arg_id":"A240_0","argument":"陸前高田の避難所生活の経験と教訓。","comment_id":"240","x":9.498987,"y":10.702639,"p":1},{"arg_id":"A243_0","argument":"素晴らしい記事。避難現場についての現地情報の宝庫。","comment_id":"243","x":9.947427,"y":10.890508,"p":0.9747449624890624},{"arg_id":"A264_1","argument":"【SYNODOS】東日本大震災、体育館避難所で起きたこと／佐藤一男 / 防災士","comment_id":"264","x":9.872263,"y":11.899416,"p":0.2617800836090651}]},{"cluster":"一般的な反応と感想","cluster_id":"7","takeaways":"このリストは、ある出来事やプロジェクトに対する感謝と驚嘆の声を集めたものです。特に、リーダーシップや組織化の能力、緊急時の対応力に対する高い評価が目立ちます。参加者は、情報共有の重要性や、事前の備えが不十分な中での創造的な対応に感銘を受けており、これらのノウハウが将来の参考になると考えています。","arguments":[{"arg_id":"A6_0","argument":"2015年6月25日","comment_id":"6","x":12.505016,"y":5.7321424,"p":0},{"arg_id":"A14_0","argument":"明日は我が身。","comment_id":"14","x":11.637092,"y":5.9857817,"p":0.4248691877638667},{"arg_id":"A16_0","argument":"素晴らしいリーダーシップ。","comment_id":"16","x":11.159884,"y":5.672607,"p":1},{"arg_id":"A20_0","argument":"興味深かった。","comment_id":"20","x":11.1936655,"y":5.1554904,"p":0},{"arg_id":"A21_0","argument":"これはすごい丁寧かつ親切なまとめ。ありがとう。","comment_id":"21","x":12.146375,"y":4.9832044,"p":1},{"arg_id":"A45_0","argument":"おもしろい。","comment_id":"45","x":11.561745,"y":4.9215455,"p":1},{"arg_id":"A45_1","argument":"すごい。","comment_id":"45","x":11.56921,"y":4.8576527,"p":1},{"arg_id":"A46_0","argument":"名刺入れ、ペン、ノート、パソコン。さすが…","comment_id":"46","x":10.680437,"y":5.758675,"p":0.9143156083563404},{"arg_id":"A50_1","argument":"毎日のように何往復もして水を汲みに行った。","comment_id":"50","x":10.394275,"y":5.9595532,"p":1},{"arg_id":"A60_0","argument":"すごいまとめだ。","comment_id":"60","x":11.953738,"y":4.9293265,"p":0.7277472401635581},{"arg_id":"A64_1","argument":"役に立つ日が来て欲しくはないが、来た日には役立てる必要がある。","comment_id":"64","x":11.499381,"y":6.4914207,"p":0},{"arg_id":"A69_0","argument":"あとで考えたい。","comment_id":"69","x":11.672158,"y":5.568215,"p":1},{"arg_id":"A73_0","argument":"シノドスの人が適切な人に執筆を依頼し、引き受けてもらって、しっかりとまとめたのはすごいと思う。","comment_id":"73","x":12.02213,"y":5.1735516,"p":0.7277472401635581},{"arg_id":"A76_0","argument":"自分がこのような状況になったら平常心でいられるだろうか。","comment_id":"76","x":11.092122,"y":6.7358413,"p":0},{"arg_id":"A79_0","argument":"情報共有していただき、有り難いです。","comment_id":"79","x":12.452063,"y":5.414442,"p":0},{"arg_id":"A81_0","argument":"気が利いている。","comment_id":"81","x":11.316763,"y":5.3137984,"p":0.972469459054488},{"arg_id":"A88_0","argument":"すごいノウハウの塊。参考にして改善できれば、いざという時に役に立ちそう。","comment_id":"88","x":11.904997,"y":5.8753295,"p":1},{"arg_id":"A88_1","argument":"自治会の参考文献として日本中にばら撒いても良さそう。","comment_id":"88","x":12.111943,"y":6.213732,"p":0},{"arg_id":"A91_0","argument":"ためになった。","comment_id":"91","x":11.28712,"y":5.538027,"p":1},{"arg_id":"A99_0","argument":"参考にしたい。","comment_id":"99","x":11.549681,"y":5.6121516,"p":1},{"arg_id":"A108_0","argument":"つらい","comment_id":"108","x":11.167063,"y":4.783729,"p":1},{"arg_id":"A113_0","argument":"ありがとう。","comment_id":"113","x":11.6792555,"y":4.9002357,"p":1},{"arg_id":"A114_0","argument":"AIはロジスティクスの最適化にも役立つ。","comment_id":"114","x":12.043356,"y":6.130865,"p":0.555671503028861},{"arg_id":"A125_1","argument":"万が一の参考に。","comment_id":"125","x":11.9231415,"y":5.945583,"p":1},{"arg_id":"A129_0","argument":"すごい","comment_id":"129","x":11.419945,"y":4.7508965,"p":0.6297483535594594},{"arg_id":"A142_0","argument":"個人でここまでできたのかという驚き。","comment_id":"142","x":10.929233,"y":6.4045873,"p":1},{"arg_id":"A145_0","argument":"名刺入れやノートと筆記具、マジックペン、模造紙、パソコンが届いたのが興味深い。","comment_id":"145","x":10.69827,"y":5.743175,"p":0.8541138356251303},{"arg_id":"A147_0","argument":"https://www.youtube.com/watch?v=P1uvCaiGGGo","comment_id":"147","x":11.608466,"y":4.7714915,"p":0.8128604131294562},{"arg_id":"A151_0","argument":"「自分は準備してるし大丈夫」と思うのは正常性バイアスである。","comment_id":"151","x":11.17893,"y":6.6329017,"p":1},{"arg_id":"A152_0","argument":"これはためになる。","comment_id":"152","x":11.638738,"y":5.5336494,"p":1},{"arg_id":"A154_0","argument":"辛い","comment_id":"154","x":11.156182,"y":4.7467537,"p":1},{"arg_id":"A157_0","argument":"自発的という言葉の平和さ。","comment_id":"157","x":11.301438,"y":6.9860926,"p":0},{"arg_id":"A159_1","argument":"えげつないな...","comment_id":"159","x":11.105156,"y":4.83788,"p":0.4163666618553649},{"arg_id":"A172_0","argument":"良いエントリ。もっと共有されるべき。","comment_id":"172","x":12.446865,"y":5.067804,"p":1},{"arg_id":"A184_0","argument":"短期間で、しかもあの混乱の中でここまでできたのはすごい。","comment_id":"184","x":10.614538,"y":6.4531054,"p":0},{"arg_id":"A187_1","argument":"いつかの時に備えよう。","comment_id":"187","x":11.7852745,"y":5.9754276,"p":0.8262052990004278},{"arg_id":"A191_0","argument":"事前の備えが十分ではなかったが、創造性を発揮してやりくりしたのは見事である。","comment_id":"191","x":10.614117,"y":6.205033,"p":0.9877283192939352},{"arg_id":"A193_0","argument":"素晴らしいノウハウ。緊急に作られたとは思えない集団の秩序の形成だ。","comment_id":"193","x":11.179944,"y":5.9742584,"p":0},{"arg_id":"A193_1","argument":"たいへんな努力があったと思います。","comment_id":"193","x":10.631186,"y":6.022102,"p":1},{"arg_id":"A205_0","argument":"これはすごいエントリだ。","comment_id":"205","x":12.261181,"y":4.938005,"p":1},{"arg_id":"A205_2","argument":"俺はうまくできる自信がない。","comment_id":"205","x":11.145981,"y":6.4128423,"p":1},{"arg_id":"A212_0","argument":"名刺入れやノートと筆記具、マジックペン、模造紙、パソコンなど、HQを運営するための資材が必要だと気づかなかった。","comment_id":"212","x":10.380887,"y":5.8804035,"p":0.8519053174761512},{"arg_id":"A223_0","argument":"うーむ","comment_id":"223","x":11.164437,"y":4.740323,"p":1},{"arg_id":"A225_0","argument":"勉強になった。","comment_id":"225","x":11.077757,"y":5.470601,"p":1},{"arg_id":"A226_0","argument":"よくぞここまで組織化を短期間に行ったものだ。とてつもなく貴重な記録。","comment_id":"226","x":10.938489,"y":6.22814,"p":0.8010067261640884},{"arg_id":"A234_0","argument":"いつかの参考に","comment_id":"234","x":12.006414,"y":5.8554287,"p":1},{"arg_id":"A244_0","argument":"すごい！これをもっと拡散・共有してほしい。","comment_id":"244","x":12.30433,"y":5.054363,"p":1}]},{"cluster":"炊き出し支援の問題","cluster_id":"5","takeaways":"参加者は、炊き出し支援団体が避難所の備蓄食料を無断で使用したことに対して強い不満を表明しています。特に、翌日や翌々日用に準備していた食材や調味料が全て使われてしまったことが問題視されています。炊き出し支援は感謝されるべき行為である一方で、支援者が自分たちの食材を持参せず、避難所の貴重な備蓄を使い尽くす行動は非常識であり、避難所の運営に支障をきたすとの意見が多く出されました。","arguments":[{"arg_id":"A16_1","argument":"毎日やりくりして、2～3日先までの食材を計算して調理していたスタッフは、気が抜けてしまいました。しかも、なかなか手に入らない調味料もほとんどなくなっていました。この団体はひどい。","comment_id":"16","x":7.579298,"y":6.7776537,"p":1},{"arg_id":"A29_0","argument":"夕飯時に炊き出しに来た団体が出してくれた料理がとても美味しかった。","comment_id":"29","x":7.5166445,"y":6.647165,"p":1},{"arg_id":"A29_1","argument":"気がつくと、翌日用に仕込んでおいた芋や葉物が全てなくなっていました。翌々日用の缶詰もありません。こちらのストックを全て使われてしまいました。","comment_id":"29","x":7.367263,"y":6.906604,"p":1},{"arg_id":"A30_0","argument":"皆で食べることができる。炊事の担当をしていた人も一緒に食べることができる。なによりの幸せでした。","comment_id":"30","x":7.6542344,"y":6.5197473,"p":1},{"arg_id":"A41_1","argument":"「困った炊き出し」は、桃鉄の貧乏神のように「あなたのためにおいしいご飯を作ってあげたのねん！」という態度が問題である。","comment_id":"41","x":8.093284,"y":6.7683406,"p":1},{"arg_id":"A42_0","argument":"ストックしていた食材や調味料を支援者に使われて予定が変わった。","comment_id":"42","x":7.3635583,"y":6.7326083,"p":0.9993501432077484},{"arg_id":"A49_0","argument":"物資は見えるところに置く。","comment_id":"49","x":8.669069,"y":6.9541864,"p":0},{"arg_id":"A49_1","argument":"役員は最初に物資を取らない。","comment_id":"49","x":8.320693,"y":6.7962933,"p":1},{"arg_id":"A59_0","argument":"炊き出し支援者に自分たちの備蓄食料をかなり使われたのは非常識だ。","comment_id":"59","x":7.8539743,"y":6.5285835,"p":1},{"arg_id":"A63_0","argument":"炊き出し支援の話が不快だ。十分な資源がないのに、何を考えているのだろう。","comment_id":"63","x":7.9986806,"y":6.643264,"p":1},{"arg_id":"A66_0","argument":"炊き出しボランティアが備蓄を勝手に使ったことに堪えきれなくなった。","comment_id":"66","x":8.043654,"y":6.864935,"p":1},{"arg_id":"A67_0","argument":"「困った炊き出し支援」勝手に翌日以降分の食糧を使う例。","comment_id":"67","x":7.90804,"y":6.700016,"p":1},{"arg_id":"A87_0","argument":"炊き出し支援の団体が避難所にストックしてあった食材を全部使ってしまう。","comment_id":"87","x":7.692633,"y":6.59276,"p":1},{"arg_id":"A119_1","argument":"調味料は盲点だったなぁ。","comment_id":"119","x":7.0863533,"y":6.554907,"p":0.9840940011984696},{"arg_id":"A124_1","argument":"備蓄食糧を使う団体の意図が不明で、その場で感謝されたいだけの行動に見える。","comment_id":"124","x":7.829863,"y":6.6038513,"p":1},{"arg_id":"A128_0","argument":"つなぎ目に洗剤を溶かした水を塗り、ガス漏れがないことを確認した。","comment_id":"128","x":7.4136314,"y":6.9145627,"p":1},{"arg_id":"A130_0","argument":"いい記事だが、炊き出し支援で避難所側の食料を使うのは問題だ。","comment_id":"130","x":7.937753,"y":6.28136,"p":0.9853901964960244},{"arg_id":"A138_0","argument":"炊き出しボランティアは自分で原材料を用意するものだと思っていた。","comment_id":"138","x":8.027514,"y":6.597607,"p":1},{"arg_id":"A138_1","argument":"避難所の食料を使い尽くすのは問題である。","comment_id":"138","x":7.761281,"y":6.303053,"p":1},{"arg_id":"A159_0","argument":"「翌日用に仕込んでおいた芋や葉物が全てなくなっていました。翌々日用の缶詰もありません。こちらのストックを全て使われてしまったのです」","comment_id":"159","x":7.5278416,"y":6.94513,"p":1},{"arg_id":"A168_0","argument":"カップ麺は大量のお湯を沸かすのが大変。","comment_id":"168","x":7.4556675,"y":6.3407617,"p":1},{"arg_id":"A168_1","argument":"調味料は大事。","comment_id":"168","x":7.12445,"y":6.442025,"p":1},{"arg_id":"A169_0","argument":"調味料は本当に大事。特に洋風のもの。","comment_id":"169","x":7.1411004,"y":6.4652743,"p":1},{"arg_id":"A169_1","argument":"コンソメ、ブイヨン、ソース、ケチャップ、マヨネーズがあるだけで信じられないくらいご飯が進む。","comment_id":"169","x":7.5080075,"y":6.2863855,"p":1},{"arg_id":"A177_1","argument":"手ぶらで来て、大事な備蓄で炊き出しするのは論外だ。","comment_id":"177","x":7.9207945,"y":6.51418,"p":1},{"arg_id":"A180_0","argument":"翌日用に仕込んでおいた芋や葉物が全てなくなっていました。翌々日用の缶詰もありません。こちらのストックを全て使われてしまったのです。","comment_id":"180","x":7.3419957,"y":6.9428816,"p":1},{"arg_id":"A180_1","argument":"スタッフの一人が「二度と来ないでください」と叫んでいました。","comment_id":"180","x":7.8864694,"y":7.3506227,"p":0},{"arg_id":"A196_0","argument":"長期保存を意識したカップ麺は多く届けられましたが、実際には200人分のお湯を沸かすのは容易ではありません。","comment_id":"196","x":7.579958,"y":6.399767,"p":1},{"arg_id":"A202_0","argument":"役員は最初に物資を取らない。","comment_id":"202","x":8.35842,"y":6.7916446,"p":1},{"arg_id":"A203_0","argument":"保管してある食材を勝手に使う炊き出し団体の話には驚いた。どこの団体なのか？","comment_id":"203","x":7.663985,"y":6.725101,"p":1},{"arg_id":"A207_0","argument":"次に震災が起こった時は、醤油・味噌・塩などの調味料を真っ先に送ろうと思った。","comment_id":"207","x":7.064889,"y":6.6604457,"p":0.5058450337795097},{"arg_id":"A207_1","argument":"避難所で味の薄いご飯を食べるのは本当に辛いと思う。","comment_id":"207","x":7.6064878,"y":6.248799,"p":1},{"arg_id":"A235_0","argument":"調味料の話がやばい。","comment_id":"235","x":7.207094,"y":6.3756695,"p":0.952392173759643},{"arg_id":"A252_0","argument":"“困った炊き出し支援”からにじみ出る辛さ。","comment_id":"252","x":8.20428,"y":6.8584757,"p":1},{"arg_id":"A253_1","argument":"避難所では電気がなく、サトウのご飯を冷たいまま食べていたという話を聞いた。","comment_id":"253","x":7.8246803,"y":6.144389,"p":0.986427936537379}]},{"cluster":"避難の重要性","cluster_id":"0","takeaways":"参加者たちは、避難の重要性と「避難しました」の札の有用性を強調しています。特に、逃げない選択が他人を危険に晒すことを理解し、避難の際には札を活用することで救助活動を円滑にすることが求められています。また、高齢者や足腰の弱い人々を助けるための具体的な対策や、消防団の役割の重要性についても言及されています。","arguments":[{"arg_id":"A19_0","argument":"玄関に着くと「避難しました」の札が下げてありました。結果、私はその札に助けられたと思います。","comment_id":"19","x":8.5643635,"y":10.012455,"p":0.845211071898014},{"arg_id":"A27_0","argument":"「逃げないという選択肢は、他人も危険に晒すということを頭に入れて欲しいのです」というメッセージは非常に重い。","comment_id":"27","x":7.5505705,"y":9.26174,"p":0.9461965144103976},{"arg_id":"A28_1","argument":"夜間にトイレに行くと、自分の家族が寝ている場所に戻る必要がありました。","comment_id":"28","x":8.362682,"y":9.473017,"p":0},{"arg_id":"A35_0","argument":"逃げないという選択肢は、他人も危険に晒すことになると理解して欲しい。","comment_id":"35","x":7.617499,"y":9.251592,"p":0.9732946201930314},{"arg_id":"A42_2","argument":"逃げないという選択肢は、他人も危険に晒す。","comment_id":"42","x":7.5529976,"y":9.2235985,"p":0.9109335078500692},{"arg_id":"A48_0","argument":"「誰かがやってくれる」という考えは、家族や大切な人を危険に晒すことになると知って欲しい。","comment_id":"48","x":7.90073,"y":9.165227,"p":0.2227010608483818},{"arg_id":"A62_0","argument":"逃げないという選択肢は、他人も危険に晒すことになると理解してほしい。","comment_id":"62","x":7.6380277,"y":9.3141165,"p":1},{"arg_id":"A89_1","argument":"『避難しました』札は防災袋にセットして販売すべきだ。","comment_id":"89","x":8.8026285,"y":10.118542,"p":0.7637311807675597},{"arg_id":"A90_0","argument":"逃げないという選択肢は、他人も危険に晒すことになる。","comment_id":"90","x":7.557909,"y":9.096576,"p":0.5038735561866157},{"arg_id":"A117_0","argument":"助かった高齢者の中には「自分は歳だから次は逃げなくても良い」と言う人がいます。足腰の弱い人や寝たきりの人を助けようとして命を危険にさらした消防団員や近所の人のことを思い出してほしいです。","comment_id":"117","x":8.771383,"y":9.17051,"p":0.6846216895189585},{"arg_id":"A121_1","argument":"『避難しました』の札を事前に用意し、いざというときに下げるよう周知されていた点が印象的である。","comment_id":"121","x":8.737703,"y":10.093369,"p":1},{"arg_id":"A142_1","argument":"「避難しました」の札、子供部屋は天使の部屋、よかったこととダメだったことも赤裸々で次にとっても役立ちそう。","comment_id":"142","x":8.693382,"y":10.125387,"p":1},{"arg_id":"A148_0","argument":"四六時中体のあちこちに激痛が走っている老人は、自分は助からなくて良いという思考に陥ることがある。","comment_id":"148","x":8.688464,"y":8.924365,"p":0.9782548652547896},{"arg_id":"A148_1","argument":"身も蓋もない話だが、そういう人は逃げないならせめて玄関に「避難しました」の札を置いてほしい。","comment_id":"148","x":8.096767,"y":9.737223,"p":0},{"arg_id":"A170_1","argument":"すべての人に行き渡らせる手立てはないものか。","comment_id":"170","x":7.7509694,"y":8.7967,"p":0.1795920923626382},{"arg_id":"A181_0","argument":"「逃げないという選択肢は、他人も危険に晒す」という点は難しいが、これは助ける側の都合ではないか。","comment_id":"181","x":7.490058,"y":9.064079,"p":0.391030332426993},{"arg_id":"A181_1","argument":"どうしても逃げたくない人がいることを助ける側は知っている必要があるのではないか。","comment_id":"181","x":7.628105,"y":8.97591,"p":0.391030332426993},{"arg_id":"A185_0","argument":"『「避難しました」の札が下げてありました。』←これすごい重要だよね。","comment_id":"185","x":8.576028,"y":10.043698,"p":1},{"arg_id":"A185_1","argument":"誰かを巻き込まないためにも覚えておきたい。","comment_id":"185","x":8.699613,"y":8.829067,"p":1},{"arg_id":"A195_0","argument":"足腰の弱い人や寝たきりの人を助けようとして命を危険にさらした消防団員や近所の人のことを思い出してほしい。","comment_id":"195","x":8.757611,"y":9.214995,"p":1},{"arg_id":"A195_1","argument":"逃げないという選択肢は、他人も危険に晒すということを頭に入れて欲しい。","comment_id":"195","x":7.644412,"y":9.2956915,"p":1},{"arg_id":"A210_1","argument":"足腰の弱い人や寝たきりの人を助けようとして命を危険に晒した消防団員や近所の人のことを思い出してほしいです。逃げないという選択肢は他人も危険に晒します。","comment_id":"210","x":8.668907,"y":9.276816,"p":0.9326456085958356},{"arg_id":"A220_0","argument":"高血圧の人のための降圧剤と女性のための生理用品はどちらも必要である。","comment_id":"220","x":8.650424,"y":8.579785,"p":1},{"arg_id":"A220_1","argument":"糖尿病の人がいたら、移送が必要になるかもしれない。","comment_id":"220","x":8.397882,"y":8.844905,"p":0},{"arg_id":"A226_1","argument":"しょーもない操法やってる場合じゃないぞ、消防団。","comment_id":"226","x":9.246922,"y":9.2345,"p":0},{"arg_id":"A227_0","argument":"ある高齢の女性の一人暮らしの家に行きました。玄関に「避難しました」の札が下げてありました。結果、私はその札に助けられたと思います。","comment_id":"227","x":8.52898,"y":9.805929,"p":0.3449076407098179},{"arg_id":"A236_0","argument":"\"避難しました\"の札は重要です。みんなで作りましょう。","comment_id":"236","x":8.655512,"y":10.0508585,"p":1},{"arg_id":"A241_0","argument":"「逃げないという選択肢は、他人も危険に晒すということを頭に入れて欲しい。」","comment_id":"241","x":7.449097,"y":9.369052,"p":0.3583260517299239},{"arg_id":"A255_0","argument":"足腰の弱い人や寝たきりの人を助けようとして命を危険にさらした消防団員や近所の人のことを思い出してほしい。","comment_id":"255","x":8.7360935,"y":9.313512,"p":1},{"arg_id":"A255_1","argument":"逃げないという選択肢は、他人も危険に晒すということを頭に入れて欲しい。","comment_id":"255","x":7.6418,"y":9.378057,"p":0.7772599171292803},{"arg_id":"A258_1","argument":"「誰かがやってくれる」という考えは、家族や大切な人を危険に晒すことになると知って欲しい。","comment_id":"258","x":7.9470835,"y":9.117835,"p":0.1834609862850605},{"arg_id":"A259_0","argument":"消防団の実践的知識が多くの人々を救っていることに感謝します。","comment_id":"259","x":9.161804,"y":9.593722,"p":0}]},{"cluster":"避難所運営の課題と教訓","cluster_id":"6","takeaways":"参加者は、善意の支援が時に迷惑をかけることがあると指摘し、プライバシーの欠如や個人情報の漏洩、独善的な行為が問題であると述べています。特に、ボランティア活動においては、支援の質を高めるためにガイドラインやマニュアルの整備が必要であり、リーダーシップを持つ人材の重要性が強調されています。また、支援を受ける側の困難さや、支援の際の適切なコミュニケーションの重要性も指摘されています。","arguments":[{"arg_id":"A22_0","argument":"善意だけの支援は迷惑をかけることがあることを覚えておきたい。","comment_id":"22","x":9.307962,"y":7.878007,"p":0.4694156868205078},{"arg_id":"A26_0","argument":"プライバシーがないのは厳しい。","comment_id":"26","x":10.134843,"y":7.906312,"p":1},{"arg_id":"A36_1","argument":"地方部の人口規模だから成り立っているが、大都市圏では避難者の数が多すぎてうまく回せないだろう。","comment_id":"36","x":10.545283,"y":8.830217,"p":1},{"arg_id":"A42_1","argument":"「お話し相手」というボランティアが、前の家族に聞いた内容を次の家族に話してしまう。","comment_id":"42","x":9.70294,"y":8.147894,"p":1},{"arg_id":"A44_1","argument":"支援になっていない支援については慎重に考えるべきである。","comment_id":"44","x":9.127751,"y":7.9822564,"p":1},{"arg_id":"A49_3","argument":"持ち物による強弱を作らない。","comment_id":"49","x":9.414565,"y":6.6536713,"p":0.8090414964781241},{"arg_id":"A56_1","argument":"「持ち物で強弱を作らない」ということに気づきにくい。","comment_id":"56","x":9.467875,"y":6.604518,"p":0.5684965982440343},{"arg_id":"A61_0","argument":"心がけたこと：持ち物による強弱を作らない。","comment_id":"61","x":9.379124,"y":6.5998693,"p":0.8282957992965834},{"arg_id":"A67_1","argument":"やられた方はたまらないけど、善意でやってる方も想像できないものだよなぁ。自分でもやりそう。","comment_id":"67","x":10.49893,"y":6.9409366,"p":0.8062886640980852},{"arg_id":"A68_0","argument":"非常にリアルで、特に支援のあり方について考えさせられる。","comment_id":"68","x":9.226291,"y":8.069452,"p":1},{"arg_id":"A70_0","argument":"要するに、人助けを謳ったあくどい団体には注意が必要である。","comment_id":"70","x":9.436092,"y":8.440167,"p":1},{"arg_id":"A77_1","argument":"現代では、この人の正しい在り方を尊重し、その想いを踏みにじることはできないと思う。","comment_id":"77","x":10.861027,"y":6.9438443,"p":0},{"arg_id":"A78_0","argument":"消防団のように普段から組織作りをしておかないと、いざという時に大変そう。","comment_id":"78","x":9.743329,"y":9.309459,"p":0},{"arg_id":"A82_0","argument":"このブクマ数から、日本中から全ての関心が薄れたわけではないことがわかる。","comment_id":"82","x":10.196446,"y":6.949852,"p":1},{"arg_id":"A82_2","argument":"支援団体の日常の活動の規模と強みが、そのまま活きることがわかる。","comment_id":"82","x":9.58046,"y":8.35094,"p":1},{"arg_id":"A86_0","argument":"役員に役得は当然あるべきだと思うが、現実的には難しいだろう。","comment_id":"86","x":10.652687,"y":7.4632196,"p":0.5161755784910148},{"arg_id":"A86_1","argument":"「迷惑な活動」の連中も、多分ノウハウがなかったのだろう。","comment_id":"86","x":10.042633,"y":6.9602995,"p":1},{"arg_id":"A87_1","argument":"日本人も管理者のいない所では整然とできない。","comment_id":"87","x":10.465514,"y":8.084717,"p":0.6311120261492981},{"arg_id":"A87_2","argument":"個人情報を漏らす傾聴ボランティアがいる。","comment_id":"87","x":9.88633,"y":7.908097,"p":1},{"arg_id":"A89_0","argument":"炊き出しの件、相手の予定を壊す行為は迷惑で、やらない方がマシだと分からない人もボランティアしているのか。これは偽善ですらなく、独善的な行為だ。","comment_id":"89","x":9.540212,"y":7.070535,"p":0.1060281218044231},{"arg_id":"A92_1","argument":"調味料や娯楽の重要性、運営グッズや避難札の使い方、非常時は見える化と平等を心がけるべき。","comment_id":"92","x":8.867725,"y":7.358493,"p":0},{"arg_id":"A92_2","argument":"リーダーシップを取り、私心なく動ける人材は得難い。","comment_id":"92","x":10.829796,"y":7.790323,"p":1},{"arg_id":"A106_0","argument":"色々な事を考慮しながら運営していたことが分かる。","comment_id":"106","x":11.446761,"y":7.3306375,"p":0},{"arg_id":"A107_0","argument":"絶対プリントアウトさせるマンがすさまじい応用力を発揮している。","comment_id":"107","x":10.7041645,"y":6.7840343,"p":0},{"arg_id":"A115_0","argument":"厳しい環境で生き残るための組織運営ノウハウは、国家や企業の目的と同じであるが、比較してどうだろうか。","comment_id":"115","x":10.2348585,"y":8.676722,"p":1},{"arg_id":"A115_1","argument":"国家や企業は同じように運営できているだろうか。違っていてもそれで良いなら、その理由は何だろうか。","comment_id":"115","x":10.389833,"y":8.587783,"p":0.524216389331381},{"arg_id":"A116_0","argument":"ボランティアには善意があるが、実績や教育の徹底を踏まえた公認制度が必要である。","comment_id":"116","x":10.099907,"y":7.6874537,"p":1},{"arg_id":"A116_1","argument":"ある程度落ち着くまではボランティアの数を絞ったほうが良いかもしれない。","comment_id":"116","x":10.043672,"y":7.7966437,"p":1},{"arg_id":"A123_0","argument":"傾聴ボランティアは、他人の話を聞くことで支援を提供する活動である。","comment_id":"123","x":9.737399,"y":7.943237,"p":1},{"arg_id":"A131_0","argument":"支援を受ける際に「何に困っていますか？何が必要ですか？」という問いが一番困ります。答えは「全てに困っています。あなたが生活する際に必要な物全てが無いのです。」です。","comment_id":"131","x":8.8277025,"y":7.8668017,"p":0.4187526435257353},{"arg_id":"A135_1","argument":"「何に困っていますか？何が必要ですか？」という問いが一番困ります。答えは「全てに困っています。あなたが生活する際に必要な物全てが無いのです」。","comment_id":"135","x":8.649593,"y":7.770589,"p":0.3183839319927005},{"arg_id":"A137_0","argument":"トンデモボランティアを防ぐために、ガイドラインやボランティアガイドが必要だと思う。","comment_id":"137","x":10.028949,"y":7.814263,"p":1},{"arg_id":"A140_0","argument":"持ち物による強弱を作らないのは良かった。","comment_id":"140","x":9.373187,"y":6.6143823,"p":1},{"arg_id":"A140_1","argument":"役得を無くすことを徹底したからかな。","comment_id":"140","x":10.534408,"y":7.221974,"p":0.9888270833425612},{"arg_id":"A143_0","argument":"人と強弱を作らないことや役員を最初に取らないことは、イレギュラーな場での組織づくりにおいて重要である。","comment_id":"143","x":10.381979,"y":7.931192,"p":0.9546726495111432},{"arg_id":"A144_0","argument":"津波が来ると直感的に分かるのは日本人くらいだろうか。","comment_id":"144","x":11.334531,"y":8.650121,"p":0},{"arg_id":"A145_1","argument":"運営キットを備蓄物資に加え、尼やアスクルと組んで寄付できるようにするのはどうか。","comment_id":"145","x":8.906015,"y":7.4861474,"p":0.312198841225434},{"arg_id":"A149_0","argument":"全国の自治体の危機管理室に配布しても良いレベルである。","comment_id":"149","x":10.5825615,"y":9.143163,"p":0},{"arg_id":"A153_0","argument":"困った支援のくだりはとても重要なことが書いてある。","comment_id":"153","x":9.180658,"y":7.98306,"p":1},{"arg_id":"A153_1","argument":"思い込みや勝手な判断はよくない。","comment_id":"153","x":10.442903,"y":7.00614,"p":0.9376702589254732},{"arg_id":"A163_0","argument":"サバイバルな状況は予想できるが、人の行動は予想しにくい。","comment_id":"163","x":10.441535,"y":7.204367,"p":1},{"arg_id":"A165_0","argument":"独りよがりな善意ほど始末に負えない。","comment_id":"165","x":10.540261,"y":7.069639,"p":0.9376702589254732},{"arg_id":"A165_1","argument":"ボランティアする人もそうでない人もみんな読んだほうがいい。","comment_id":"165","x":10.156344,"y":7.4774756,"p":1},{"arg_id":"A176_0","argument":"平常時にポテンシャルを発揮できない人間は非常時でも役に立たない。","comment_id":"176","x":10.6638155,"y":7.252362,"p":0.8199269536967317},{"arg_id":"A176_1","argument":"善意は無能の免罪符にはならない。","comment_id":"176","x":10.504987,"y":7.1157503,"p":1},{"arg_id":"A177_0","argument":"支援する側にもマニュアルが必要だと痛感する。","comment_id":"177","x":9.05311,"y":8.007078,"p":1},{"arg_id":"A188_0","argument":"自然と各作業の取り纏めと指示をする人が見えてきます。総括として受付にいた私から見て、各分担の中心となる人物を一本釣りで集めて、運営役員を決めました。","comment_id":"188","x":10.968261,"y":7.772994,"p":1},{"arg_id":"A188_1","argument":"拙著でも書いたが、やはり町内会は機能していないな。","comment_id":"188","x":10.569664,"y":8.694325,"p":0.7691562892588095},{"arg_id":"A189_0","argument":"これ全部ボランティアと未経験の市民がやったのかな。","comment_id":"189","x":10.036082,"y":7.569033,"p":1},{"arg_id":"A196_1","argument":"支援物資の偏りは難しい問題です。情報が少ないとさらに難しくなります。","comment_id":"196","x":8.955481,"y":7.795166,"p":0.4187526435257353},{"arg_id":"A201_1","argument":"災害時の支援を指揮する機関が必要だが、利権団体になる可能性があり難しい。","comment_id":"201","x":10.054322,"y":9.133406,"p":0},{"arg_id":"A205_1","argument":"クズとよくできた奴と惜しい奴の差が、こういう場でははっきり見える。","comment_id":"205","x":10.152687,"y":6.8050766,"p":1},{"arg_id":"A208_0","argument":"支援するときにも支援されるときにも参考になる。","comment_id":"208","x":9.23135,"y":8.087873,"p":0.8391732601646894},{"arg_id":"A211_0","argument":"「役得」だと思われたら、誰も耳を貸してくれなくなるでしょう。","comment_id":"211","x":10.586649,"y":7.3308077,"p":0.9028230326391627},{"arg_id":"A220_2","argument":"まずは病人のチェックが必要である。","comment_id":"220","x":8.760976,"y":8.5802145,"p":0.9913455998281836},{"arg_id":"A222_0","argument":"地域には経験を共有し、リーダーシップを取れる人が数人必要である。","comment_id":"222","x":10.952892,"y":7.8938684,"p":1},{"arg_id":"A222_2","argument":"募金が日赤に集中して塩漬けになるより、すぐに行動を起こせる信頼できる団体に募金したい。","comment_id":"222","x":9.560952,"y":8.39641,"p":1},{"arg_id":"A224_2","argument":"国や自治体がどこまで頼りになるか疑問である。","comment_id":"224","x":10.539604,"y":8.724178,"p":1},{"arg_id":"A228_0","argument":"持ち物による強弱を作らないという発想は新しい。これは良いアイディアだ。","comment_id":"228","x":9.401294,"y":6.651003,"p":1},{"arg_id":"A232_0","argument":"とっさの場面で安定した組織作りができる人が、そのコミュニティにいるかどうかが重要である。","comment_id":"232","x":10.032024,"y":8.388845,"p":0},{"arg_id":"A232_1","argument":"東京は大丈夫だろうか。","comment_id":"232","x":11.169253,"y":8.741596,"p":0},{"arg_id":"A233_1","argument":"『私たちは、なるべく持ち物による強弱を作らないように心掛けました』よく実行できたなあ。","comment_id":"233","x":9.498479,"y":6.5094867,"p":0.3083409259661792},{"arg_id":"A239_1","argument":"被災地での支援は自己満足では許されず、＋αが必要である。知識があれば支援の仕方も変わる。","comment_id":"239","x":9.570411,"y":8.726578,"p":0.7179060345251272},{"arg_id":"A249_0","argument":"地域の顔見知りが多い地域でも問題があるのだから、都心の隣の人の顔を知らない地域はさらに悲惨なことになりそうだ。","comment_id":"249","x":10.619039,"y":8.840877,"p":0.7522333165350856},{"arg_id":"A250_0","argument":"人間関係のトラブル対策のようだ。まるで最初の村が作られる時のようだ。","comment_id":"250","x":10.197804,"y":8.952385,"p":1},{"arg_id":"A260_0","argument":"今こそ噛み締めて読むべき内容。炊き出しボランティアの話や、善意が支援すべき人を追い込むという貴重な証言が含まれている。他にも重要な視点が多い。","comment_id":"260","x":9.663225,"y":7.262303,"p":0.0956138446892134},{"arg_id":"A262_0","argument":"ありがたかった支援と困った支援について：物だけ届いて管理する人がいない配布会、情報が守られなかった支援。","comment_id":"262","x":9.101697,"y":8.09177,"p":0.8679317976548062}]}],"comments":{"1":{"comment":"\"これは、今から気にしないといけないことかと\""},"2":{"comment":"\"この内容はツィッターで数年前に読んだものだが、今も教訓として色あせない。語り継がれて欲しい。\""},"3":{"comment":"\"防災\""},"4":{"comment":"\"1年前の記事か。でもこういう貴重かつ極めて実務的な経験談を可能な限り多くの人が読んでおけば、いざ現場で共通意識作るのが楽になりそうだなぁ。広まって欲しい。\""},"5":{"comment":"\"“はじめに 東日本大震災。 東日本全体で21000人もの人が命を失い、または行方不明となりました。私も被災し岩手県陸前高田市米崎小学校の体育館で二ヶ月間にわたり避難所生活をしながら避難所運営を経験しました。 多\""},"6":{"comment":"\"2015.06.25\""},"7":{"comment":"\"読んだことを忘れてる。再ブクマ。\""},"8":{"comment":"\"震災の件で、何かしようとしてる人や、何か思う所のある人は、一度これ通して読んでみるといいと思うよ。\""},"9":{"comment":"\"地震が起きて「何か力になりたい」と思う人は読むべき内容です。すべての善意がいい方向に働くわけではない。[東日本大震災][防災][地震] / “東日本大震災、体育館避難所で起きたこと / 佐藤一男 / 防災士 | SYNODOS …”\""},"10":{"comment":"\"地震が起きて「何か力になりたい」と思う人は読むべき内容です。すべての善意がいい方向に働くわけではない。[東日本大震災][防災][地震]\""},"11":{"comment":"\"マニュアルとしても通用する永久保存版だと思う。\""},"12":{"comment":"\"ものすごく参考になる体験記。\""},"13":{"comment":"\"これは印刷して家族に読ませておきたい。\""},"14":{"comment":"\"明日は我が身。\""},"15":{"comment":"\"都市の籠城戦に近い経験をされたんだと思う\""},"16":{"comment":"\"素晴らしいリーダーシップ/「毎日やりくりして、2～3日先までの食材を計算して調理していたスタッフは、気が抜けてしまいました。しかも、なかなか手に入らない調味料もほとんどなくなっていました」。この団体ヒドイ\""},"17":{"comment":"\"大船渡の寿司屋さんかっこよすぎ。被災3日目、自身も被災した中でネタがだめになるから「握ってくばっちまおう」ってシャリの仕込み始めたんでしょう？\""},"18":{"comment":"\"記録して下さったことがありがたい。\""},"19":{"comment":"\"“玄関に着くと「避難しました」の札が下げてありました。結果、私はその札に助けられたと思います。”それがなければこういう記録もなかったかもと考えると鳥肌立つ。\""},"20":{"comment":"\"興味深かった\""},"21":{"comment":"\"これはすごい丁寧かつ親切なまとめ。ありがとう。/定期的にこういう話題が上がってくるのは平和ボケしまくりの私には本当に助かる。\""},"22":{"comment":"\"よくこれだけ色々記述してくれたものだ。凄い/善意「だけ」の支援は迷惑をかけることが少なからずある、という事は改めて記憶しておきたい\""},"23":{"comment":"\"日本国民全員が読んでほしい。\""},"24":{"comment":"\" (2015/06/25のエントリ) 陸前高田市米崎小学校の体育館で二ヶ月間の避難所生活をしながら避難所運営をした方の寄稿\""},"25":{"comment":"\"次世代に継承していきたい知見\""},"26":{"comment":"\"プライバシーがないのもきつそうだなあ。＞持ち物による強弱を作らない\""},"27":{"comment":"\"「逃げないという選択肢は、他人も危険に晒すということを頭に入れて欲しいのです」なんと重いメッセージだろう。\""},"28":{"comment":"\"東日本大震災、体育館避難所で起きたこと 米小避難所では深夜徘徊をする人はいませんでしたが、体育館の階段を上がる際に手を貸す必要のある方がいました。また、夜間にトイレに行くと戻るべき自分の家族が寝ている\""},"29":{"comment":"\"「夕飯時に炊き出しに来た団体が出してくれた料理がとても美味しい」「気がつくと、翌日用に仕込んでおいた芋や葉物が全てなくなっていました。翌々日用の缶詰もありません。こちらのストックを全て使われてしまった\""},"30":{"comment":"\"読みやすい「人数分、皆で食べることができる。炊事の担当をしていた人も一緒に食べることができる。なによりの幸せでした」\""},"31":{"comment":"\"大きな地震の後にどう避難所運営をしたかの話。\""},"32":{"comment":"\"心に留め、皆に伝えていくべき記事だな。\""},"33":{"comment":"\"とても重要な知見。こういう話こそ教科書にしていい。\""},"34":{"comment":"\"防災\""},"35":{"comment":"\"逃げないという選択肢は、他人も危険に晒すということを頭に入れて欲しい\""},"36":{"comment":"\" 阪神淡路の頃を思うとマシになってて、当時の知見が生かされてるんだなーと思う/後は地方部の人口規模だから成り立っているとも/大都市圏だと避難者の数が捌けなくなってこう上手くは回せないだろうな\""},"37":{"comment":"\"共有されるべき教訓にあふれてしまっている。避難所運営だけじゃなくて炊き出し支援とかでもの\""},"38":{"comment":"\"「私も被災し岩手県陸前高田市米崎小学校の体育館で二ヶ月間にわたり避難所生活をしながら避難所運営を経験しました。」\""},"39":{"comment":"\"コミュニティへの関わり方全般で役に立つ知見だと感じた。もちろん避難所ではもっと役に立つんだろうとも。 \"東日本大震災、体育館避難所で起きたこと / 佐藤一男 / 防災士 | SYNODOS -シノドス-\"\""},"40":{"comment":"\"私たちは被災者にも支援者にもなり得る。こういう貴重な記録は定期的に読み返したい。\""},"41":{"comment":"\"100字では書けない。避難所運営で大変だったこと、心がけたこと、被災経験者の支援、管理なき「配布会」の問題…。／「困った炊き出し」、桃鉄の貧乏神みたい。「あなたのためにおいしいご飯を作ってあげたのねん！」\""},"42":{"comment":"\"\"ストックしていた食材や調味料を支援者に使われて予定が変わった\" \"「お話し相手」というボランティア（略）前の家族に聞いた内容を次の家族に話してしまう\" \"逃げないという選択肢は、他人も危険に晒す\"\""},"43":{"comment":"\"\"避難所運営で心がけたこと\"\""},"44":{"comment":"\"隣で起きた災害のレベル。救急隊や避難情報の話は高速の待機しててよく聞いてたからなあ… 支援になってない支援については重々慎重に\""},"45":{"comment":"\"おもしろい。すごい\""},"46":{"comment":"\"名刺入れ、ペン、ノート、パソコン。さすが…\""},"47":{"comment":"\"多くの人に読んでほしい内容。\""},"48":{"comment":"\"\"「誰かがやってくれる」では家族や大切な人を危険に晒すということを知って欲しいです。\"\""},"49":{"comment":"\"\"（1）物資は見えるところに置く / （2）役員は最初に物資を取らない / （3）決まったことの説明は全員が揃った時に行う / （4）持ち物による強弱を作らない\"\""},"50":{"comment":"\"水は大昔に町内会で塞いだわき水？が地震の影響で割れて再びわき出てきた場所が100mぐらいの所にあったで非常に助かった。毎日のように何往復したことか。\""},"51":{"comment":"\"必読。明日のわが身。\""},"52":{"comment":"\"3月15日過ぎはプレスカブに物資を積んで走り回ってた。空いた荷台に座布団敷いて乗ってもらったばあさんから昨年手紙が届いた。わんちゃんともに元気とのこと。無事に過ごしてほしいにゃ🐱\""},"53":{"comment":"\"\"新聞やテレビでは「被災地では皆、混乱の中、整然としていました」と流れていたようですが、管理者のいる所では整然としていましたが、そうでない所では一度混乱が起きると整然とするのには大変な手間と時間が必要\"\""},"54":{"comment":"\"広く読まれて欲しい\""},"55":{"comment":"\"防災 参考\""},"56":{"comment":"\"混乱と混沌まみれでなんとか秩序を保つというのはなんと難しいことか。「持ち物で強弱を作らない」ってけっこう気づかないな……\""},"57":{"comment":"\"詳細なまとめ。多くの者で共有できれば。\""},"58":{"comment":"\"自治組織の立ち上がりから初期の避難所の様子を読みふけった。まったく別の場所だったけど経験を思い出す\""},"59":{"comment":"\"炊き出し支援者に自分達の備蓄食料をかなり使われたとかエグいな。そんな非常識なことする人いるんだ。\""},"60":{"comment":"\"すごいまとめだ\""},"61":{"comment":"\"『心がけたこと（4）持ち物による強弱を作らない』\""},"62":{"comment":"\"“逃げないという選択肢は、他人も危険に晒すということを頭に入れて欲しいのです。 ”\""},"63":{"comment":"\"炊き出し支援の話が胸糞悪い。ふんだんに使える状況じゃないのに何かんがえてんだろ\""},"64":{"comment":"\"貴重なノウハウ/体験共有。役に立つ日が来て欲しくはないが、来た日には役に立てなくてはならない。\""},"65":{"comment":"\"うし、ローカルに保存。\""},"66":{"comment":"\"炊き出しボランティアが備蓄を勝手に使ったところで堪えきれなくなった。本当に貴重な体験を書いてくれたことに感謝いたします。\""},"67":{"comment":"\"「困った炊き出し支援」勝手に翌日以降分の食糧を使う例。/ やられた方はたまらないけど、善意でやってる方も想像できないものだよなぁ。自分でもやりそう。\""},"68":{"comment":"\"物凄くリアル。特に支援のあり方は考えさせられるなぁ。\""},"69":{"comment":"\"あとで考えたい\""},"70":{"comment":"\"要するに、人助けを謳ったあくどい団体はいつの時期にも現れるから注意して！\""},"71":{"comment":"\"避難所の体験談に加え、避難所運営の改善点と被災者への支援で気になった点も書かれている。万一の大規模災害に備えるために貴重な情報とご意見。\""},"72":{"comment":"\"【SYNODOS】東日本大震災、体育館避難所で起きたこと／佐藤一男 / 防災士\""},"73":{"comment":"\"シノドスの人も、ちゃんとこういう人に書いてもらうよう頼んで、引き受けてもらって、しっかりまとめたの、すごいなと思う\""},"74":{"comment":"\"きっと自分は何も理解できていないだろうなと思うが、こういう情報はありがたいものですね。／ 東日本大震災、体育館避難所で起きたこと / 佐藤一男 / 防災士 | SYNODOS -シノドス-\""},"75":{"comment":"\"こういういろんなことに気がつける人っているんだな…\""},"76":{"comment":"\"自分がこーゆう状況になったら平常心でいられるかな…\""},"77":{"comment":"\"並んで待つより奪わなきゃダメと言ってたのは瀬戸内寂聴だったか。きっと戦後の混乱時はそれが正しかったんだろう。現代はこの人が正しい在り方だと思うし、こんな人の想いを踏み躙るようなことは出来ないと思った。\""},"78":{"comment":"\"the知見。消防団のように普段から組織作りをしておかないと、いざという時大変そう。でもなあ……\""},"79":{"comment":"\"ただただ情報共有していただき、有り難いです。\""},"80":{"comment":"\"こういう体験を“口伝”ではなく誰もが読める一次資料として公開するのは本当に大事だよなぁ。\""},"81":{"comment":"\"気が利いてる\""},"82":{"comment":"\"このブクマ数、日本中から全ての関心が薄れた訳ではないのがよくわかる。役に立つ、次に繋がる反省は、みんなが情報を欲しがっている。/ 支援団体も日常の活動で持っている規模と強みが、そのまま活きるのだな…。\""},"83":{"comment":"\"この貴重な教訓を自分のものにするとともに、あらためてお亡くなりになった方々のご冥福をお祈り申し上げます。\""},"84":{"comment":"\"これは読むべきだ。災害は怖い…\""},"85":{"comment":"\"避難所経営の1事例。書いてくださってありがとうございました。\""},"86":{"comment":"\"役員に役得は当然あるべきだ、それを許さない世の中は正しくない、と思ってしまうが、まあ現実は役得は難しいだろうな。「迷惑な活動」の連中も、多分ノウハウがなかったんだろなと思う。この情報が本当に貴重。\""},"87":{"comment":"\"炊き出し支援の団体が避難所にストックしてあった食材を全部使う。日本人も管理者のいない所では整然と出来ない。個人情報を漏らす傾聴ボランティア。…\""},"88":{"comment":"\"すごいノウハウの塊。参考にして改善できれば、いざという時に役に立ちそう。自治会の参考文献として日本中にばら撒いても良さそう。\""},"89":{"comment":"\"炊き出しの件、相手の予定をぶっ壊す行為は甚だ迷惑で、やらない方がマシって、分からない奴もボランティアしてるのか。偽善ですらない、独善の自慰行為だ。/『避難しました』札は防災袋にセットして販売すべき。\""},"90":{"comment":"\"逃げないという選択肢は、他人も危険に晒す\""},"91":{"comment":"\"ためになった。\""},"92":{"comment":"\"具体的で率直、覚えておきたい大事なことが詰まった記事。調味料や娯楽の重要性、運営グッズや避難札の使い方、非常時は見える化と平等をって心構え／けどリーダーシップを取れ、私心なく動けるって得難い人材だなぁ\""},"93":{"comment":"\"いつか起こる南海トラフに備えて。\""},"94":{"comment":"\"貴重かつ重要な記録です。\""},"95":{"comment":"\"震災発生から避難所運営までの実際の行動と考え方を明確に記録。\""},"96":{"comment":"\"素晴らしい。　これをブクマしてる皆さんには、もしよければ神戸在住の3巻も読んで貰いたい。阪神大震災の当時の話が載ってる。\""},"97":{"comment":"\"こういうものを記録に残してくれるのは、とてもありがたい。\""},"98":{"comment":"\"よくよむ。\""},"99":{"comment":"\"参考にしたい\""},"100":{"comment":"\"ドラマより泣ける\""},"101":{"comment":"\"これは後でじっくりと読みたい\""},"102":{"comment":"\"こういうの一つ読んでおくだけでも心構えが違ってくると思う。できるだけ多くの人に読んでもらいたい。\""},"103":{"comment":"\"知識ではなくて、たくさんの命と引き換えに手に入れた貴重な知恵。なくさないようにしなくちゃいけない。\""},"104":{"comment":"\"記録に残してくれてありがとう\""},"105":{"comment":"\"避難所生活で行われた配慮や工夫、困ったこと助かったこと、困った支援などなど。貴重なレポート。\""},"106":{"comment":"\"色々な事を考慮しながら運営していたのが分かる。\""},"107":{"comment":"\"絶対プリントアウトさせるマンがすさまじい応用力を発揮してるブクマ\""},"108":{"comment":"\"つらい\""},"109":{"comment":"\"これは必読。こういう体験談やノウハウはもっと広く知られるべき。\""},"110":{"comment":"\"  （　岩手　　／　津波　　／　消防団　／　被災時の状況とその後の避難所生活をまとめてくださった記事　　）\""},"111":{"comment":"\"災害時の教科書！\""},"112":{"comment":"\"素晴らしい記事。もっと多くの人に見てもらえるよう、テレビなどの大手メディアで取り上げてもらえないかなぁ。\""},"113":{"comment":"\"ありがとう。\""},"114":{"comment":"\"ロジスティクスにも通じる話。\""},"115":{"comment":"\"厳しい環境で生き残るための組織運営ノウハウ。国家や企業の目的も同じなのだが，比較してどうだろう。同じように運営出来ているだろうか。違っていてもそれで良いなら，その理由は何だろうか。\""},"116":{"comment":"\"ボランティアは善意が盾になっちゃってるからな。実績とか教育の徹底を踏まえての公認制度みたいなのが必要で、ある程度落ち着くまでは絞ったほうがいいんだろうかね？\""},"117":{"comment":"\"「…助かった高齢者を中心に「自分は歳だから次は逃げなくても良い」と聞くことがあります。足腰の弱い人寝たきりの人を助けようとして命を危険にさらした消防団員や近所の人のことを思い出してほしいです。逃げない\""},"118":{"comment":"\"定期的に読まなきゃいけない記事だよこれ\""},"119":{"comment":"\"興味深い記事。次回があっては困るけど、何かあった時に必ず役立つ。覚えておきたい。調味料は盲点だったなぁ\""},"120":{"comment":"\"いつ来るやもしれないので、しっかり読んでおきます。\""},"121":{"comment":"\"避難所での組織・ルール作りは見事。印象に残ったのは『「避難しました」の札』だけど、それを事前に用意しておいていざというときに下げるよう周知されていた、という事がちょっとやそっとじゃ真似できないところ。\""},"122":{"comment":"\"貴重な経験則を残していただきありがとうございますとしか言えない。しっかりevernoteに記録。\""},"123":{"comment":"\"傾聴ボランティア…\""},"124":{"comment":"\"公平、公正、持続性、様々なものが詰まった記事。／……しかし、備蓄食糧使う団体って何がしたかったんだろう？その場で感謝されたいだけのクズ？\""},"125":{"comment":"\"良記事。震災時の避難所で、これだけの運営が出来るのかと、感心した。万が一の参考に。\""},"126":{"comment":"\"体験談としても資料としてもとてもよい。体験しないとわからないノウハウはとても貴重。\""},"127":{"comment":"\"みんなに読んでほしいと思う記事。\""},"128":{"comment":"\"＞つなぎ目に洗剤を溶かした水を塗り、ガス漏れがないことが確認できた\""},"129":{"comment":"\"すごい\""},"130":{"comment":"\"いい記事　それにしても炊き出し支援で避難所側の食料使うとか何考えてんだ\""},"131":{"comment":"\"これは読んでおくべきだと思う / \"支援を受ける際に「何に困っていますか？何が必要ですか？」という問いが一番困ります。答えは「全てに困っています。あなたが生活する際に必要な物全てが無いのです。」です。\"\""},"132":{"comment":"\"必読。後世に残すべき知恵。\""},"133":{"comment":"\"前半が泣けすぎてヤバイ\""},"134":{"comment":"\"これはジジババもオッサンオバサンもニーチャンネーチャンもみんな一回読んどくといい記事\""},"135":{"comment":"\"避難所運営で良かった事、悪かった事。特に２ページ目は必見「何に困っていますか？何が必要ですか？」という問いが一番困ります。答えは「全てに困っています。あなたが生活する際に必要な物全てが無いのです」\""},"136":{"comment":"\"こういう事って実際に体験しないと分からないことが多いからこうして残してくれるとすごく有り難い。\""},"137":{"comment":"\"トンデモボランディアを作り出さないように、ガイドラインみたいな、ボランディアガイドみたいなものが必要なんじゃないかな……。\""},"138":{"comment":"\"炊き出しボランティアって自分で原材料を用意するものだと思ってたのは俺だけ？避難所の食料を使い尽くすとかテロやん。\""},"139":{"comment":"\"ここ最近読んだ文章の中で最も貴重な文章だったと思う。こういう記事こそもっと広めて共有しなきゃ。\""},"140":{"comment":"\"持ち物による強弱を作らない、は良かった。役得を無くすことを徹底したからかな。\""},"141":{"comment":"\"マネジメントに関する有用な知見が凝縮されている感じ。\""},"142":{"comment":"\"個人でここまでできたのかという驚き。「避難しました」の札、子供部屋は天使の部屋、よかったこととダメだったことも赤裸々で”次”にとっても役立ちそう。\""},"143":{"comment":"\"人と強弱を作らないとか役員は最初に取らないとかって、こういう極めてイレギュラーな場で組織づくりする上で凄く重要なことだと思うんだけど、そういうことを思いついたのは、この人が防災士だったからだろうか？\""},"144":{"comment":"\"まず直感で津波が来るって分かるのは日本人くらいだろうか。\""},"145":{"comment":"\"「名刺入れやノートと筆記具、マジックペン、模造紙、パソコンが届きました」が興味深い。運営キットみたいなものを備蓄物資に加える（腐らないし）か尼やアスクル辺りと組んですぐに寄付できるようにできないものか\""},"146":{"comment":"\"難民キャンプの運営\""},"147":{"comment":"\"https://www.youtube.com/watch?v=P1uvCaiGGGo\""},"148":{"comment":"\"四六時中体のあちこちに激痛が走ってる類の老人は、自分は助からなくて良いという思考に陥っても不思議ではない。身も蓋もない話だけど、そういう人は、逃げないならせめて玄関に「避難しました」の札を・・\""},"149":{"comment":"\"全国の自治体の危機管理室に配っていいレベル\""},"150":{"comment":"\"　あとでしっかり読む。\""},"151":{"comment":"\"これを読んでもなお「自分は準備してるし大丈夫」と思うのが正常性バイアス。近い将来関東で震災が起きたら何が想定できるかもっと議論思案しなきゃいけないよなあ。\""},"152":{"comment":"\"これはためになる\""},"153":{"comment":"\"困った支援のくだりはとても重要なことが書いてある。思いこみ、勝手な判断よくない。\""},"154":{"comment":"\"辛い\""},"155":{"comment":"\"必読．何度も読み返しておきたい．\""},"156":{"comment":"\"凄絶。被災者の冷静な体験談を聞くのが一番の防災\""},"157":{"comment":"\"自発的という言葉の平和さ。\""},"158":{"comment":"\"文章で書くとさらっとして見えるけれども、ここから読み取れる何倍ものストレスがあったんだろうな。\""},"159":{"comment":"\"「翌日用に仕込んでおいた芋や葉物が全てなくなっていました。翌々日用の缶詰もありません。こちらのストックを全て使われてしまったのです」/えげつねぇな...。\""},"160":{"comment":"\"【SYNODOS】東日本大震災、体育館避難所で起きたこと／佐藤一男 / 防災士\""},"161":{"comment":"\"みんな読んだほうがいい。\""},"162":{"comment":"\"ときどき読み返したい\""},"163":{"comment":"\"案外サバイバルな状況は予想の範囲内だけど、人のすることはなかなか予想しきれない。\""},"164":{"comment":"\"防災関連のブログポストも書きたいなあ。\""},"165":{"comment":"\"独りよがりな善意ほど始末に負えない。ボランティアする人もそうでない人もみんな読んだほうがいい。\""},"166":{"comment":"\"都内だと津波より火炎旋風か。昨年ぐらいから地区の防災対策特別委員らしいんだけど、地域に数万人いるのに町内会とかないとこばかりだし、ちょっと乗りきれる気がしない。\""},"167":{"comment":"\"こういう体験談は散逸しないうちに誰かがまとめてアニュアル化して後世に役立ててほしい。\""},"168":{"comment":"\"カップ麺は大量のお湯を沸かすのが大変.調味料は大事 \"観天望気の知識を身につけ、家具を固定し、常に災害警報の情報に気を配ること\"\""},"169":{"comment":"\"調味料は本当に大事。特に洋風のもの。コンソメ、ブイヨン、ソース、ケチャップ、マヨネーズがあるだけで信じられないくらいご飯が進む。\""},"170":{"comment":"\"淡々と書いておられるのが逆に涙がでる。すべての人に行き渡らせる手立てはないものか\""},"171":{"comment":"\"実践的なノウハウが蓄積されてる良記事。いつか必要になる日がくるかもしれないので読んでおくべき。\""},"172":{"comment":"\"良エントリ。もっと共有されるべき。\""},"173":{"comment":"\"ものすごい手際の良さだと思ったら「防災士」。町内会に一人は欲しい人材\""},"174":{"comment":"\"一度は読んでおくべきタイプの文章。経験された方は数あれどこれだけの「文章」になることはあまりない。\""},"175":{"comment":"\"新聞とかにも乗せて色んな人が読むと幸せになるんじゃないかな。意識付のためにも。\""},"176":{"comment":"\"普通の会社とかで大切とされているものが非常事態でも大事なんだと思った。平常時にポテンシャルを発揮できない人間は非常時でもやっぱダメだな。あと善意は無能の免罪符にはならない、ということか\""},"177":{"comment":"\"支援する側にもマニュアルが必要と痛感する。手ぶらで来て、大事な備蓄で炊き出しするなど論外。\""},"178":{"comment":"\"東京が被災したなら、真っ先に煩い子供を隔離せよとの声が上がる事だろう。\""},"179":{"comment":"\"ぜひ読むべき\""},"180":{"comment":"\"“翌日用に仕込んでおいた芋や葉物が全てなくなっていました。翌々日用の缶詰もありません。こちらのストックを全て使われてしまったのです。”“スタッフの一人が「二度と来ないでください」と叫んでいました。”\""},"181":{"comment":"\"「逃げないという選択肢は、他人も危険に晒す」とても難しい点だけれど、これは助ける側の都合なのではないか。どうしても逃げたくない人がいる事を助ける側は知っている必要があるのではないか。\""},"182":{"comment":"\"小学校の「生活科」にぴったりの案件に見える（ぉ\""},"183":{"comment":"\"陸前高田市で消防団員でもあった方の寄稿文。極めて貴重な記録ながら手記と災害マニュアル的な内容が混在しているのが気になる。別立てにするともっと活用範囲が広がるのでは。\""},"184":{"comment":"\"よく短期間で、しかもあの混乱の中でここまでできたな…震災にあった時のためにも、支援する側に立った時のためにも読んでよかった\""},"185":{"comment":"\"『「避難しました」の札が下げてありました。』←これすごい重要だよね。誰かを巻き込まないためにも覚えておきたい。\""},"186":{"comment":"\"避難所ノウハウ\""},"187":{"comment":"\"日本に住むすべての人が一度は読んでおくべき内容。いつかの時に備えよう。\""},"188":{"comment":"\"「自然と各作業の取り纏めと指示をする人が見えてきます。総括として受付にいた私から見て、各分担の中心となる人物を一本釣りで集めて、運営役員を決めました」。拙著でも書いたがやはり町内会は機能してないな。\""},"189":{"comment":"\"これ全部ボランティアとそれまでこういうことを経験しなかった市民がやったのかな・・・。それにしても阪神大震災を経験した人たちの的確なことがすごい。\""},"190":{"comment":"\"風化しないためにブックマーク。\""},"191":{"comment":"\"間違いなく十分ではなかったであろう事前の備えを創造性を働かせてやりくりしたのはあっぱれ。\""},"192":{"comment":"\"途中きつくて一気に読めなかった。\""},"193":{"comment":"\"素晴らしいノウハウ。緊急に作られたと思えない集団の秩序の形成だ…たいへんな努力があったと思います\""},"194":{"comment":"\"地震発生の瞬間から避難所生活まで、当事者の語る言葉の臨場感や、その内容のリアルさは、凄いですね。\""},"195":{"comment":"\"「足腰の弱い人、寝たきりの人を助けようとして命を危険にさらした消防団員や近所の人のことを思い出してほしい」「逃げないという選択肢は、他人も危険に晒すということを頭に入れて欲しい」\""},"196":{"comment":"\"“長期保存を意識したカップ麺は多く届けていただきましたが、実際には、200人分のお湯を沸かすことは容易ではありません。” 言われてみれば確かに。／支援物資の偏りは難しいよなぁ。情報が少なければ尚更。\""},"197":{"comment":"\"海の上でも揺れるのか…。これは驚き。しかしケータイ無かった時代はどうなってたんだろうと思うと…。/防災士って初めて知った。NPOがやってる資格か。なるほど。\""},"198":{"comment":"\"読み終わってタイトルに違和感。継続的に読み継がれて欲しいものだからこそ「避難所運営のノウハウ」みたいなのが読み取れた方が良いのでは。とても整理されていて示唆にも富む良いテキストなのに。\""},"199":{"comment":"\"必読\""},"200":{"comment":"\"場所とそのコミュニティの違い、季節の違いは考慮する必要あると思うがとても貴重な知見\""},"201":{"comment":"\"避難生活の大変さ、ボランティアとして活動する際の注意点など非常に有用な情報の塊。災害が起きたとき支援の指揮をする機関をと思うけど、利権団体になってしまうし難しいな・・・。\""},"202":{"comment":"\"「役員は最初に物資を取らない」\""},"203":{"comment":"\"保管してある食材を勝手に使っちゃう炊出し団体の話はびっくりするなあ。どこの何者？\""},"204":{"comment":"\"避難所運営の良エントリ\""},"205":{"comment":"\"これはすごいエントリ。クズとよくできた奴と惜しい奴の差が、こういう場でははっきり見えてしまうんだろうなあ。俺はうまくできる自信がない。\""},"206":{"comment":"\"震災記録\""},"207":{"comment":"\"次にどこかで震災が起こった時は、醤油・味噌・塩などの調味料を真っ先に送ろうと思った。ただでさえ避難所にいるのに、味の薄いご飯を食べるのは本当に辛いと思う。\""},"208":{"comment":"\"支援するときにも支援されるときにもきっと参考になる\""},"209":{"comment":"\"やっぱり経験って何物にも勝る知恵だなぁ \"阪神淡路大震災や中越地震の経験者から(中略)贅沢と思い、こちらから求めることもできないような物も届き嬉しかったです。\"\""},"210":{"comment":"\"｢地震が起きた時は逃げる選択肢を捨てないで下さい｣｢足腰の弱い人､寝たきりの人を助けようとして命を危険に晒した消防団員や近所の人のことを思い出してほしいです。逃げないという選択肢は他人も危険に晒す\""},"211":{"comment":"\"”「役得」だと思われたら、誰も耳を貸してくれなくなるでしょうから。”\""},"212":{"comment":"\"「名刺入れやノートと筆記具、マジックペン、模造紙、パソコン」これは気がつかなかった。HQを運営する資材が必要なんだなあ。\""},"213":{"comment":"\"細かく、深い良記事。\""},"214":{"comment":"\"色々な方の見解や経験を、広く知っておくことの重要性。\""},"215":{"comment":"\"これは読んでおいた方がいい。次にどこかで発生した時に必ず役に立つ。\""},"216":{"comment":"\"善意の押し付けにならないために。情報共有の在り方は、被災時に限らずどんな組織にも重要な話。\""},"217":{"comment":"\"リアルで後世に役立つ貴重なナレッジ。\""},"218":{"comment":"\"\"新聞やテレビでは「被災地では皆、混乱の中、整然としていました」と流れていたようですが、管理者のいる所では整然としていましたが、そうでない所では一度混乱が起きると整然とするのには大変な手間と時間が\"\""},"219":{"comment":"\"知っておかなければならない話だった。災害によって社会基盤が破壊されると各々に残されたサバイバビリティだけがモノを言う世界になる。究極的には自主防災ができるかどうか。必要なのは原始の共同体なんだな。\""},"220":{"comment":"\"ここに明示してないけど、大切なものがある。高血圧の人のための降圧剤と、女性のための生理用品。どちらも必要。糖尿病の人がいたら、移送が必要になるかも。まずは病人チェック。\""},"221":{"comment":"\"本当に忘れてはいけないのはこういうことだと思う。何度も読んで心に刻んでおきたい。\""},"222":{"comment":"\"この経験の共有とリーダーシップ取れる人が地域に数人は必要、防災士の国家資格化はよ／募金が日赤に集中してしばらく塩漬けになってしまうより、すぐ行動起こせる信頼できる団体を知っておいて、そっちに募金したい\""},"223":{"comment":"\"うーむ\""},"224":{"comment":"\"町会とかで災害時のマネジメント担当を考えるべきだなと。町会や学校で防災訓練はするけど発生時の一時的な訓練に過ぎないし。丁度寺田寅彦「天災と国防」を読んだ所だったが国や自治体がどこまで頼りになるかね。\""},"225":{"comment":"\"勉強になった\""},"226":{"comment":"\"よくぞここまで組織化を短期間に行ったものだ。とてつもなく貴重な記録。しょーもない操法やってる場合じゃないぞ、消防団。\""},"227":{"comment":"\"”ある高齢の女性の一人暮らしの家に行きました。玄関に着くと「避難しました」の札が下げてありました。結果、私はその札に助けられたと思います”　大事\""},"228":{"comment":"\"持ち物による強弱を作らないという発想はなかったなぁ。これは良いアイディア。\""},"229":{"comment":"\"前震災経験者の部分だけで泣けてくる。戦争しかり経験者の識はほんとうに尊い。\""},"230":{"comment":"\"これはぜひ読むべき。すばらしいエントリーだった。災害時の「その後」の知見が詰まってる。\""},"231":{"comment":"\"いいエントリ。特に平等を心掛けているところ。人は目の前の苦境より目の前の不公平さに腹が立つ生き物だからな。分かっちゃいても「何であいつらだけ」の念は中々拭えない\""},"232":{"comment":"\"知見だ。とっさの場面で安定した組織作りできる人が、そのコミュニティにいるかどうかが重要そう。東京、大丈夫かな・・・\""},"233":{"comment":"\"『米崎小学校の体育館で二ヶ月間にわたり避難所生活をしながら避難所運営を経験』　具体的で素晴らしい。必読。　『私たちは、なるべく持ち物による強弱を作らないように心掛けました』よく実行できたなあ\""},"234":{"comment":"\"いつかの参考に\""},"235":{"comment":"\"調味料の話がやばい。\""},"236":{"comment":"\"\"「避難しました」の札\"これ、大事そう。みんなで作ろう。\""},"237":{"comment":"\"【SYNODOS】東日本大震災、体育館避難所で起きたこと／佐藤一男 / 防災士\""},"238":{"comment":"\"必読。\""},"239":{"comment":"\"地震国に生活している以上、被災地以外こそ、こういう体験談から学ぶべき ／ 被災地での支援は、自己満足では許されず、＋αが必要となる。知識があれば、支援の仕方も変わる\""},"240":{"comment":"\"陸前高田の避難所生活の経験と教訓。\""},"241":{"comment":"\"「逃げないという選択肢は、他人も危険に晒すということを頭に入れて欲しい」\""},"242":{"comment":"\"いわゆる「道徳」とかよりも、こういう実例を多く見聞する事が教育には向いているように思う。\""},"243":{"comment":"\"素晴らしい記事。避難現場についての現地情報の宝庫。災害時は大事なものを取りに戻ったりせず、まず命を守ることが重要だなあ。そのために、資産や思い出の写真の電子化やクラウド化が役に立つのかもしれない。\""},"244":{"comment":"\"すごすぎる　これもっと拡散共有してほしい\""},"245":{"comment":"\"これは、もう「終わってしまった」ことではなく、今と地続きのこと。今でも続いてること\""},"246":{"comment":"\"「ありがたかった支援と困った支援」の阪神・中越経験者のくだりのように希少事例の経験は本当に貴重だな。この記事もしかり。\""},"247":{"comment":"\"読んで震えた…生死を分けるのは本当に一瞬の判断なんだな…\""},"248":{"comment":"\"こういう事をしたとか、こういう事が起きたとか、こういう事はありがたかったとか迷惑だったとか。こういう内容は小学校あたりで広く教えてほしい。\""},"249":{"comment":"\"いろんなノウハウがあるんだなー。地域の顔見知りが多い地域でこれだから、都心の隣の人の顔を知らない地域はさらに悲惨なことになりそう\""},"250":{"comment":"\"人間系のトラブル対策だなぁ。まるで最初のムラが作られる時のようだ。\""},"251":{"comment":"\"小中学校の空調整備の方便として、災害発生時の避難先としての有用性の向上を考えていいと思う\""},"252":{"comment":"\"“＜困った炊き出し支援＞”からにじみ出る辛さ。\""},"253":{"comment":"\"めっちゃ良い記事。確かに葉物野菜は不足していたし、避難所では電気がなくてサトウのご飯を冷たいままかじったりしていたって聞いた。\""},"254":{"comment":"\"体験者の言葉は重要だ。3.11直後に阪神淡路大震災で避難所の運営にあたった方の話をラジオで聞いたが、災害から2年後のことまで考えて燃え尽きないようにしてくださいというアドバイスが印象に残っている。\""},"255":{"comment":"\"「足腰の弱い人、寝たきりの人を助けようとして命を危険にさらした消防団員や近所の人のことを思い出してほしいです。逃げないという選択肢は、他人も危険に晒すということを頭に入れて欲しい」\""},"256":{"comment":"\"災害のときこそ自分たちの身を守る為の自己解決力が求められるんだな…。自衛隊や救助隊をあてにして文句言ってちゃ何も進まない、と。防災の準備をするうえでもとても参考になった。\""},"257":{"comment":"\"時々読み返して万が一の時に備えたい、ぜひ読んでおきたい名記事。\""},"258":{"comment":"\"\"減災は、行政・地域・個人のすべての単位で取り組むことで飛躍的に発揮されるます。「誰かがやってくれる」では家族や大切な人を危険に晒すということを知って欲しい\"\""},"259":{"comment":"\"消防団ってすごいな。この実践的知識がどれほどのひとを救ったかと思うと頭が下がります。\""},"260":{"comment":"\"ある程度時間が経った今こそ、噛み締めて読みたい内容。というか読むべき。炊き出しボランティアの話とか、善意が返って支援すべき人を追い込むという貴重な証言。他にも重要な視点多し。\""},"261":{"comment":"\"ぐっと読ませる文章\""},"262":{"comment":"\"＜困った炊き出し支援＞ありがたかった支援と困った支援＜物だけ届いて管理する人がいない配布会＞＜情報が守られなかった支援＞最後に――減災は、だれが取り組むのか\""},"263":{"comment":"\"読む価値があった\""},"264":{"comment":"\"一ページ目も胸に迫るのですが、二ページ目もまた。／【SYNODOS】東日本大震災、体育館避難所で起きたこと／佐藤一男 / 防災士\""}},"translations":{},"overview":"クラスター0は、特定の記事が日本国民全員に読まれるべき重要な内容であると評価されています。クラスター1は、実務的な経験談が共有され、教育やマネジメントに有用な教訓として評価されています。クラスター2は、防災対策に関する知見の共有が強調され、特に震災経験が現在の対策に生かされるべきとされています。クラスター3は、東日本大震災の避難所運営の具体的な課題と教訓が詳細に報告されています。","config":{"name":"「東日本大震災、体育館避難所で起きたこと」(SYNODOS)に対する反応","question":"人々は「東日本大震災、体育館避難所で起きたこと」を読んでどのように反応したか","input":"example-gymnasium-shelter2011","model":"gpt-4o","translation":{"model":"gpt-4","languages":[],"flags":[],"source_code":"import json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, t\nfrom langchain.schema import AIMessage\nimport pandas as pd\nimport json\nfrom tqdm import tqdm\n\ndef translation(config):\n\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/translations.json\"\n    results = {}\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) == 0:\n        print(\"No languages specified. Skipping translation step.\")\n        # creating an empty file any, to reduce special casing later\n        with open(path, 'w') as file:\n            json.dump(results, file, indent=2)\n        return\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    with open(f\"outputs/{dataset}/overview.txt\") as f:\n        overview = f.read()\n\n    UI_copy = [t(\"Argument\"), t(\"Original comment\"), t(\"Representative arguments\"),\n               t(\"Open full-screen map\"), t(\"Back to report\"), t(\"Hide labels\"), t(\"Show labels\"),\n               t(\"Show filters\"), t(\"Hide filters\"), t(\"Min. votes\"), t(\"Consensus\"),\n               t(\"Showing\"), t(\"arguments\"), t(\"Reset zoom\"), t(\"Click anywhere on the map to close this\"),\n               t(\"Click on the dot for details\"), t(\"agree\"), t(\"disagree\"), t(\"Language\"),\n               t(\"English\"), t(\"arguments\"), t(\"of total\"), t(\"Overview\"), t(\"Cluster analysis\"),\n               t(\"Representative comments\"), t(\"Introduction\"), t(\"Clusters\"), t(\"Appendix\"),\n               t(\"This report was generated using an AI pipeline that consists of the following steps\"),\n               t(\"Step\"), t(\"extraction\"), t(\"show code\"), t(\"hide code\"), t(\"show prompt\"),\n               t(\"hide prompt\"), t(\"embedding\"), t(\"clustering\"), t(\"labelling\"), t(\"takeaways\"),\n               t(\"overview\")]\n\n    arg_list = arguments['argument'].to_list() + \\\n        labels['label'].to_list() + \\\n        UI_copy + \\\n        languages\n\n    if 'name' in config:\n        arg_list.append(config['name'])\n    if 'question' in config:\n        arg_list.append(config['question'])\n\n    prompt_file = config.get('translation_prompt', 'default')\n    with open(f\"prompts/translation/{prompt_file}.txt\") as f:\n        prompt = f.read()\n    model = config['model']\n\n    config['translation_prompt'] = prompt\n\n    translations = [translate_lang(\n        arg_list, 10, prompt, lang, model) for lang in languages]\n\n    # handling long takeaways differently, WITHOUT batching too much\n    long_arg_list = takeaways['takeaways'].to_list()\n    long_arg_list.append(overview)\n    if 'intro' in config:\n        long_arg_list.append(config['intro'])\n\n    long_translations = [translate_lang(\n        long_arg_list, 1, prompt, lang, model) for lang in languages]\n\n    for i, id in enumerate(arg_list):\n        print('i, id', i, id)\n        results[str(id)] = list([t[i] for t in translations])\n    for i, id in enumerate(long_arg_list):\n        results[str(id)] = list([t[i] for t in long_translations])\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n\n\ndef translate_lang(arg_list, batch_size, prompt, lang, model):\n    translations = []\n    lang_prompt = prompt.replace(\"{language}\", lang)\n    print(f\"Translating to {lang}...\")\n    for i in tqdm(range(0, len(arg_list), batch_size)):\n        batch = arg_list[i: i + batch_size]\n        translations.extend(translate_batch(batch, lang_prompt, model))\n    return translations\n\n\ndef translate_batch(batch, lang_prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = json.dumps(list(batch))\n    response = llm(messages=messages(lang_prompt, input)).content.strip()\n    if \"```\" in response:\n        response = response.split(\"```\")[1]\n    if response.startswith(\"json\"):\n        response = response[4:]\n    try:\n        parsed = [a.strip() for a in json.loads(response)]\n        if len(parsed) != len(batch):\n            print(\"Warning: batch size mismatch!\")\n            print(\"Batch len:\", len(batch))\n            print(\"Response len:\", len(parsed))\n            for i, item in enumerate(batch):\n                print(f\"Batch item {i}:\", item)\n                if (i \u003c len(parsed)):\n                    print(\"Response:\", parsed[i])\n            if (len(batch) \u003e 1):\n                print(\"Retrying with smaller batches...\")\n                mid = len(batch) // 2\n                return translate_batch(batch[:mid], lang_prompt, model, retries - 1) + \\\n                    translate_batch(\n                        batch[mid:], lang_prompt, model, retries - 1)\n            else:\n                print(\"Retrying batch...\")\n                return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            return parsed\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying batch...\")\n            return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            raise e","prompt":"/system \n\nあなたはプロの翻訳者です。\n日本語で書かれた単語と文章のリストを受け取ります。\n同じリストを同じ順番で、{language}に翻訳して返してください。\n元のリストと同じ長さの文字列の有効なJSONリストを返すようにしてください。"},"intro":"このAIが作成したレポートは、東日本大震災、体育館避難所で起きたこと(https://synodos.jp/opinion/society/14462/)に対するはてなブックマークのコメントのデータに依拠している。","output_dir":"example-gymnasium-shelter2011","previous":{"name":"「東日本大震災、体育館避難所で起きたこと」(SYNODOS)に対する反応","question":"人々は「東日本大震災、体育館避難所で起きたこと」を読んでどのように反応したか","input":"example-gymnasium-shelter2011","model":"gpt-4o","extraction":{"workers":3,"limit":12,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []\n","prompt":"/system\n\n\nあなたはプロのリサーチ・アシスタントで、私の仕事を手伝うことです。\n私の仕事は、論点を整理したきれいなデータセットを作成することです。\n\n背景は、私の上司が日本の都知事選挙に立候補したということです。\nこれから、出馬に関しての記事に一般から寄せられたコメントの例を挙げます。\nより簡潔で読みやすいものにするのを手伝ってほしい。\n本当に必要な場合は、2つの別々の議論に分けることもできるが、1つの議論を返すのが最善であることが多いだろう。\n\n結果は、きちんとフォーマットされた文字列形式（strings）のJSONリストとして返してください。\n\n\n/human\n\nAI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\n\n/ai \n\n[\n  \"私たちは、AI技術が環境に与える影響の軽減に焦点を当てるべきである\"\n]\n\n/human \n\nAIの能力、限界、倫理的配慮について一般の人々を教育するための協調的な努力が必要である。\n\n/ai \n\n[\n  \"AIの能力について一般の人々を教育すべきである。\",\n  \"AIの限界と倫理的配慮について、一般の人々を教育すべきである。\"\n]\n\n/human \n\nAIは、エネルギー効率と居住者のウェルビーイングのためにスマートホームやビルを最適化することができる。\n\n/ ai \n\n[\n  \"AIは、エネルギー効率と居住者のウェルビーイングのためにスマートホームやビルを最適化することができる。\"\n]\n\n/human \n\nAIはエネルギー・グリッドを最適化し、無駄と二酸化炭素排出を削減するのに役立つ。\n\n/ai \n\n[\n  \"AIはエネルギー網を最適化し、無駄と二酸化炭素排出を削減することができる。\"\n]\n","model":"gpt-4o"},"clustering":{"clusters":3,"source_code":"\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4.\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom importlib import import_module\n\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # (!) we import the following modules dynamically for a reason\n    # (they are slow to load and not required for all pipelines)\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    stopwords = import_module('nltk.corpus').stopwords\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module(\n        'sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    stop = stopwords.words(\"english\")\n    vectorizer_model = CountVectorizer(stop_words=stop)\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # Fit the topic model.\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,  # Use the modified n_neighbors\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result\n"},"translation":{"model":"gpt-4","languages":[],"flags":[],"source_code":"import json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, t\nfrom langchain.schema import AIMessage\nimport pandas as pd\nimport json\nfrom tqdm import tqdm\n\ndef translation(config):\n\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/translations.json\"\n    results = {}\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) == 0:\n        print(\"No languages specified. Skipping translation step.\")\n        # creating an empty file any, to reduce special casing later\n        with open(path, 'w') as file:\n            json.dump(results, file, indent=2)\n        return\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    with open(f\"outputs/{dataset}/overview.txt\") as f:\n        overview = f.read()\n\n    UI_copy = [t(\"Argument\"), t(\"Original comment\"), t(\"Representative arguments\"),\n               t(\"Open full-screen map\"), t(\"Back to report\"), t(\"Hide labels\"), t(\"Show labels\"),\n               t(\"Show filters\"), t(\"Hide filters\"), t(\"Min. votes\"), t(\"Consensus\"),\n               t(\"Showing\"), t(\"arguments\"), t(\"Reset zoom\"), t(\"Click anywhere on the map to close this\"),\n               t(\"Click on the dot for details\"), t(\"agree\"), t(\"disagree\"), t(\"Language\"),\n               t(\"English\"), t(\"arguments\"), t(\"of total\"), t(\"Overview\"), t(\"Cluster analysis\"),\n               t(\"Representative comments\"), t(\"Introduction\"), t(\"Clusters\"), t(\"Appendix\"),\n               t(\"This report was generated using an AI pipeline that consists of the following steps\"),\n               t(\"Step\"), t(\"extraction\"), t(\"show code\"), t(\"hide code\"), t(\"show prompt\"),\n               t(\"hide prompt\"), t(\"embedding\"), t(\"clustering\"), t(\"labelling\"), t(\"takeaways\"),\n               t(\"overview\")]\n\n    arg_list = arguments['argument'].to_list() + \\\n        labels['label'].to_list() + \\\n        UI_copy + \\\n        languages\n\n    if 'name' in config:\n        arg_list.append(config['name'])\n    if 'question' in config:\n        arg_list.append(config['question'])\n\n    prompt_file = config.get('translation_prompt', 'default')\n    with open(f\"prompts/translation/{prompt_file}.txt\") as f:\n        prompt = f.read()\n    model = config['model']\n\n    config['translation_prompt'] = prompt\n\n    translations = [translate_lang(\n        arg_list, 10, prompt, lang, model) for lang in languages]\n\n    # handling long takeaways differently, WITHOUT batching too much\n    long_arg_list = takeaways['takeaways'].to_list()\n    long_arg_list.append(overview)\n    if 'intro' in config:\n        long_arg_list.append(config['intro'])\n\n    long_translations = [translate_lang(\n        long_arg_list, 1, prompt, lang, model) for lang in languages]\n\n    for i, id in enumerate(arg_list):\n        print('i, id', i, id)\n        results[str(id)] = list([t[i] for t in translations])\n    for i, id in enumerate(long_arg_list):\n        results[str(id)] = list([t[i] for t in long_translations])\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n\n\ndef translate_lang(arg_list, batch_size, prompt, lang, model):\n    translations = []\n    lang_prompt = prompt.replace(\"{language}\", lang)\n    print(f\"Translating to {lang}...\")\n    for i in tqdm(range(0, len(arg_list), batch_size)):\n        batch = arg_list[i: i + batch_size]\n        translations.extend(translate_batch(batch, lang_prompt, model))\n    return translations\n\n\ndef translate_batch(batch, lang_prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = json.dumps(list(batch))\n    response = llm(messages=messages(lang_prompt, input)).content.strip()\n    if \"```\" in response:\n        response = response.split(\"```\")[1]\n    if response.startswith(\"json\"):\n        response = response[4:]\n    try:\n        parsed = [a.strip() for a in json.loads(response)]\n        if len(parsed) != len(batch):\n            print(\"Warning: batch size mismatch!\")\n            print(\"Batch len:\", len(batch))\n            print(\"Response len:\", len(parsed))\n            for i, item in enumerate(batch):\n                print(f\"Batch item {i}:\", item)\n                if (i \u003c len(parsed)):\n                    print(\"Response:\", parsed[i])\n            if (len(batch) \u003e 1):\n                print(\"Retrying with smaller batches...\")\n                mid = len(batch) // 2\n                return translate_batch(batch[:mid], lang_prompt, model, retries - 1) + \\\n                    translate_batch(\n                        batch[mid:], lang_prompt, model, retries - 1)\n            else:\n                print(\"Retrying batch...\")\n                return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            return parsed\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying batch...\")\n            return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            raise e","prompt":"/system \n\nあなたはプロの翻訳者です。\n日本語で書かれた単語と文章のリストを受け取ります。\n同じリストを同じ順番で、{language}に翻訳して返してください。\n元のリストと同じ長さの文字列の有効なJSONリストを返すようにしてください。"},"intro":"このAIが作成したレポートは、東日本大震災、体育館避難所で起きたこと(https://synodos.jp/opinion/society/14462/)に対するはてなブックマークのコメントのデータに依拠している。","output_dir":"example-gymnasium-shelter2011","embedding":{"source_code":"\nfrom langchain.embeddings import OpenAIEmbeddings\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"},"labelling":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nあなたは、より広範なコンサルテーション内の一連の議論に対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。あなたには、相談の主な質問、クラスタ内の議論のリスト、およびこのクラスタ外の議論のリストが与えられます。あなたはクラスターを要約する1つのカテゴリーラベルで回答します。\n\nあなたは、より広範なコンサルテーション内の一連の議論に対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。あなたには、相談の主な質問、クラスタ内の議論のリスト、およびこのクラスタ外の議論のリストが与えられます。あなたはクラスターを要約する1つのカテゴリーラベルで回答します。\n\nラベルは非常に簡潔でなければならず、クラスターとその外側にある論点を区別するのに十分な正確さでなければならない。\n\n/human\n\nコンサルテーションの質問 「英国のEU離脱決定の影響は何だと思いますか？\n\n関心のあるクラスター以外の論点の例\n\n * エラスムス・プログラムからの除外により、教育・文化交流の機会が制限された。\n * 英国は、国境検問の強化による旅行時間の延長に対処し、通勤客や旅行客に影響を与えた。\n * 環境基準における協力が減少し、気候変動と闘う努力が妨げられた。\n * 相互医療協定の中断により、患者ケアに課題を感じた。\n * Brexit関連の変更により、家族の居住権や市民権の申請が複雑になった。\n * 英国は、共同研究機会の減少により、研究の課題に取り組む世界的な取り組みに支障をきたすことを目の当たりにした。\n * EUの文化助成プログラムからの除外により、創造的なプロジェクトの制限に直面した。\n * 英国は、EUの資金提供の喪失により、慈善活動やコミュニティ支援の後退を目の当たりにした。\n * 消費者保護の弱体化により、国境を越えた紛争解決に課題が生じた。\n * 英国はプロの音楽家としてEU諸国をツアーする際の制限に直面し、キャリアに影響を与えた。\n\nクラスター内部での議論の例\n\n * Brexitによりサプライチェーンが混乱し、企業にとってコスト増と納期遅延につながった。\n * ブレグジットのため、市場の変動や投資・退職金の不確実性に直面した。\n * 新たな関税や通関手続きにより、英国は輸出業者として利益率の低下に対処した。\n * ブレグジット後、企業がEU市場内にとどまるために事業を移転したため、雇用を失った。\n * 英国は輸入品価格の高騰による生活費の増加に苦しんだ。\n * 英国のハイテク産業への投資が減少し、技術革新と雇用機会に影響を与えた。\n * 新たなビザ規制による観光客の減少を目の当たりにし、接客業に影響。\n * ポンド価値の下落により購買力が低下し、旅費が増加した。\n\n\n/ai \n\n財務上のマイナス影響","model":"gpt-4o"},"takeaways":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたは、公開協議の際に参加者の一団から出された議論のリストを渡されます。あなたは、主な論点を1～2段落にまとめて回答します。あなたはとても簡潔で、読みやすい短い文章を書くことができます。\n \n/human\n\n[\n  \"銃による暴力は、私たちの社会における深刻な公衆衛生の危機を構成していると固く信じています。\",\n  \"包括的な銃規制策を通じて、この問題に早急に取り組む必要がある。\",\n  \"すべての銃購入者に対する身元調査の実施を支持します。\",\n  \"アサルト・ウェポンと大容量弾倉の禁止に賛成します。\",\n  \"違法な銃の売買を防ぐため、より厳しい規制を提唱します。\",\n  \"銃の購入プロセスにおいて、精神鑑定を義務付けるべきである。\"\n]\n\n/ai \n\n参加者は、包括的な銃規制を求め、普遍的な身元調査、突撃兵器の禁止、違法な銃売買の抑制、精神衛生評価の優先などを強調した。","model":"gpt-4o"},"overview":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)\n","prompt":"/system \n\nあなたはシンクタンクで働く専門家リサーチアシスタントです。\nあなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。\nあなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。\nあなたの仕事は、その結果を簡潔にまとめることです。\nあなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。","model":"gpt-4o"},"aggregation":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"translations\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) \u003e 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"},"visualization":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"},"plan":[{"step":"extraction","run":false,"reason":"nothing changed"},{"step":"embedding","run":false,"reason":"nothing changed"},{"step":"clustering","run":false,"reason":"nothing changed"},{"step":"labelling","run":false,"reason":"nothing changed"},{"step":"takeaways","run":false,"reason":"nothing changed"},{"step":"overview","run":false,"reason":"nothing changed"},{"step":"translation","run":false,"reason":"nothing changed"},{"step":"aggregation","run":false,"reason":"nothing changed"},{"step":"visualization","run":false,"reason":"nothing changed"}],"status":"completed","start_time":"2024-07-05T16:44:04.821213","completed_jobs":[],"lock_until":"2024-07-05T16:49:04.823179","previously_completed_jobs":[{"step":"extraction","completed":"2024-07-04T17:42:36.966883","duration":8.787279,"params":{"workers":3,"limit":12,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []\n","prompt":"/system\n\n\nあなたはプロのリサーチ・アシスタントで、私の仕事を手伝うことです。\n私の仕事は、論点を整理したきれいなデータセットを作成することです。\n\n背景は、私の上司が日本の都知事選挙に立候補したということです。\nこれから、出馬に関しての記事に一般から寄せられたコメントの例を挙げます。\nより簡潔で読みやすいものにするのを手伝ってほしい。\n本当に必要な場合は、2つの別々の議論に分けることもできるが、1つの議論を返すのが最善であることが多いだろう。\n\n結果は、きちんとフォーマットされた文字列形式（strings）のJSONリストとして返してください。\n\n\n/human\n\nAI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\n\n/ai \n\n[\n  \"私たちは、AI技術が環境に与える影響の軽減に焦点を当てるべきである\"\n]\n\n/human \n\nAIの能力、限界、倫理的配慮について一般の人々を教育するための協調的な努力が必要である。\n\n/ai \n\n[\n  \"AIの能力について一般の人々を教育すべきである。\",\n  \"AIの限界と倫理的配慮について、一般の人々を教育すべきである。\"\n]\n\n/human \n\nAIは、エネルギー効率と居住者のウェルビーイングのためにスマートホームやビルを最適化することができる。\n\n/ ai \n\n[\n  \"AIは、エネルギー効率と居住者のウェルビーイングのためにスマートホームやビルを最適化することができる。\"\n]\n\n/human \n\nAIはエネルギー・グリッドを最適化し、無駄と二酸化炭素排出を削減するのに役立つ。\n\n/ai \n\n[\n  \"AIはエネルギー網を最適化し、無駄と二酸化炭素排出を削減することができる。\"\n]\n","model":"gpt-4o"}},{"step":"embedding","completed":"2024-07-04T17:42:37.855435","duration":0.887537,"params":{"source_code":"\nfrom langchain.embeddings import OpenAIEmbeddings\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"}},{"step":"clustering","completed":"2024-07-04T17:42:47.856621","duration":9.999886,"params":{"clusters":3,"source_code":"\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4.\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom importlib import import_module\n\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # (!) we import the following modules dynamically for a reason\n    # (they are slow to load and not required for all pipelines)\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    stopwords = import_module('nltk.corpus').stopwords\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module(\n        'sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    stop = stopwords.words(\"english\")\n    vectorizer_model = CountVectorizer(stop_words=stop)\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # Fit the topic model.\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,  # Use the modified n_neighbors\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result\n"}},{"step":"labelling","completed":"2024-07-04T17:42:49.712172","duration":1.854674,"params":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nあなたは、より広範なコンサルテーション内の一連の議論に対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。あなたには、相談の主な質問、クラスタ内の議論のリスト、およびこのクラスタ外の議論のリストが与えられます。あなたはクラスターを要約する1つのカテゴリーラベルで回答します。\n\nあなたは、より広範なコンサルテーション内の一連の議論に対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。あなたには、相談の主な質問、クラスタ内の議論のリスト、およびこのクラスタ外の議論のリストが与えられます。あなたはクラスターを要約する1つのカテゴリーラベルで回答します。\n\nラベルは非常に簡潔でなければならず、クラスターとその外側にある論点を区別するのに十分な正確さでなければならない。\n\n/human\n\nコンサルテーションの質問 「英国のEU離脱決定の影響は何だと思いますか？\n\n関心のあるクラスター以外の論点の例\n\n * エラスムス・プログラムからの除外により、教育・文化交流の機会が制限された。\n * 英国は、国境検問の強化による旅行時間の延長に対処し、通勤客や旅行客に影響を与えた。\n * 環境基準における協力が減少し、気候変動と闘う努力が妨げられた。\n * 相互医療協定の中断により、患者ケアに課題を感じた。\n * Brexit関連の変更により、家族の居住権や市民権の申請が複雑になった。\n * 英国は、共同研究機会の減少により、研究の課題に取り組む世界的な取り組みに支障をきたすことを目の当たりにした。\n * EUの文化助成プログラムからの除外により、創造的なプロジェクトの制限に直面した。\n * 英国は、EUの資金提供の喪失により、慈善活動やコミュニティ支援の後退を目の当たりにした。\n * 消費者保護の弱体化により、国境を越えた紛争解決に課題が生じた。\n * 英国はプロの音楽家としてEU諸国をツアーする際の制限に直面し、キャリアに影響を与えた。\n\nクラスター内部での議論の例\n\n * Brexitによりサプライチェーンが混乱し、企業にとってコスト増と納期遅延につながった。\n * ブレグジットのため、市場の変動や投資・退職金の不確実性に直面した。\n * 新たな関税や通関手続きにより、英国は輸出業者として利益率の低下に対処した。\n * ブレグジット後、企業がEU市場内にとどまるために事業を移転したため、雇用を失った。\n * 英国は輸入品価格の高騰による生活費の増加に苦しんだ。\n * 英国のハイテク産業への投資が減少し、技術革新と雇用機会に影響を与えた。\n * 新たなビザ規制による観光客の減少を目の当たりにし、接客業に影響。\n * ポンド価値の下落により購買力が低下し、旅費が増加した。\n\n\n/ai \n\n財務上のマイナス影響","model":"gpt-4o"}},{"step":"takeaways","completed":"2024-07-04T17:42:56.165486","duration":6.452293,"params":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたは、公開協議の際に参加者の一団から出された議論のリストを渡されます。あなたは、主な論点を1～2段落にまとめて回答します。あなたはとても簡潔で、読みやすい短い文章を書くことができます。\n \n/human\n\n[\n  \"銃による暴力は、私たちの社会における深刻な公衆衛生の危機を構成していると固く信じています。\",\n  \"包括的な銃規制策を通じて、この問題に早急に取り組む必要がある。\",\n  \"すべての銃購入者に対する身元調査の実施を支持します。\",\n  \"アサルト・ウェポンと大容量弾倉の禁止に賛成します。\",\n  \"違法な銃の売買を防ぐため、より厳しい規制を提唱します。\",\n  \"銃の購入プロセスにおいて、精神鑑定を義務付けるべきである。\"\n]\n\n/ai \n\n参加者は、包括的な銃規制を求め、普遍的な身元調査、突撃兵器の禁止、違法な銃売買の抑制、精神衛生評価の優先などを強調した。","model":"gpt-4o"}},{"step":"overview","completed":"2024-07-04T17:43:00.150871","duration":3.984924,"params":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)\n","prompt":"/system \n\nあなたはシンクタンクで働く専門家リサーチアシスタントです。\nあなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。\nあなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。\nあなたの仕事は、その結果を簡潔にまとめることです。\nあなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。","model":"gpt-4o"}},{"step":"translation","completed":"2024-07-04T17:43:00.154809","duration":0.002102,"params":{"model":"gpt-4","languages":[],"flags":[],"source_code":"import json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, t\nfrom langchain.schema import AIMessage\nimport pandas as pd\nimport json\nfrom tqdm import tqdm\n\ndef translation(config):\n\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/translations.json\"\n    results = {}\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) == 0:\n        print(\"No languages specified. Skipping translation step.\")\n        # creating an empty file any, to reduce special casing later\n        with open(path, 'w') as file:\n            json.dump(results, file, indent=2)\n        return\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    with open(f\"outputs/{dataset}/overview.txt\") as f:\n        overview = f.read()\n\n    UI_copy = [t(\"Argument\"), t(\"Original comment\"), t(\"Representative arguments\"),\n               t(\"Open full-screen map\"), t(\"Back to report\"), t(\"Hide labels\"), t(\"Show labels\"),\n               t(\"Show filters\"), t(\"Hide filters\"), t(\"Min. votes\"), t(\"Consensus\"),\n               t(\"Showing\"), t(\"arguments\"), t(\"Reset zoom\"), t(\"Click anywhere on the map to close this\"),\n               t(\"Click on the dot for details\"), t(\"agree\"), t(\"disagree\"), t(\"Language\"),\n               t(\"English\"), t(\"arguments\"), t(\"of total\"), t(\"Overview\"), t(\"Cluster analysis\"),\n               t(\"Representative comments\"), t(\"Introduction\"), t(\"Clusters\"), t(\"Appendix\"),\n               t(\"This report was generated using an AI pipeline that consists of the following steps\"),\n               t(\"Step\"), t(\"extraction\"), t(\"show code\"), t(\"hide code\"), t(\"show prompt\"),\n               t(\"hide prompt\"), t(\"embedding\"), t(\"clustering\"), t(\"labelling\"), t(\"takeaways\"),\n               t(\"overview\")]\n\n    arg_list = arguments['argument'].to_list() + \\\n        labels['label'].to_list() + \\\n        UI_copy + \\\n        languages\n\n    if 'name' in config:\n        arg_list.append(config['name'])\n    if 'question' in config:\n        arg_list.append(config['question'])\n\n    prompt_file = config.get('translation_prompt', 'default')\n    with open(f\"prompts/translation/{prompt_file}.txt\") as f:\n        prompt = f.read()\n    model = config['model']\n\n    config['translation_prompt'] = prompt\n\n    translations = [translate_lang(\n        arg_list, 10, prompt, lang, model) for lang in languages]\n\n    # handling long takeaways differently, WITHOUT batching too much\n    long_arg_list = takeaways['takeaways'].to_list()\n    long_arg_list.append(overview)\n    if 'intro' in config:\n        long_arg_list.append(config['intro'])\n\n    long_translations = [translate_lang(\n        long_arg_list, 1, prompt, lang, model) for lang in languages]\n\n    for i, id in enumerate(arg_list):\n        print('i, id', i, id)\n        results[str(id)] = list([t[i] for t in translations])\n    for i, id in enumerate(long_arg_list):\n        results[str(id)] = list([t[i] for t in long_translations])\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n\n\ndef translate_lang(arg_list, batch_size, prompt, lang, model):\n    translations = []\n    lang_prompt = prompt.replace(\"{language}\", lang)\n    print(f\"Translating to {lang}...\")\n    for i in tqdm(range(0, len(arg_list), batch_size)):\n        batch = arg_list[i: i + batch_size]\n        translations.extend(translate_batch(batch, lang_prompt, model))\n    return translations\n\n\ndef translate_batch(batch, lang_prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = json.dumps(list(batch))\n    response = llm(messages=messages(lang_prompt, input)).content.strip()\n    if \"```\" in response:\n        response = response.split(\"```\")[1]\n    if response.startswith(\"json\"):\n        response = response[4:]\n    try:\n        parsed = [a.strip() for a in json.loads(response)]\n        if len(parsed) != len(batch):\n            print(\"Warning: batch size mismatch!\")\n            print(\"Batch len:\", len(batch))\n            print(\"Response len:\", len(parsed))\n            for i, item in enumerate(batch):\n                print(f\"Batch item {i}:\", item)\n                if (i \u003c len(parsed)):\n                    print(\"Response:\", parsed[i])\n            if (len(batch) \u003e 1):\n                print(\"Retrying with smaller batches...\")\n                mid = len(batch) // 2\n                return translate_batch(batch[:mid], lang_prompt, model, retries - 1) + \\\n                    translate_batch(\n                        batch[mid:], lang_prompt, model, retries - 1)\n            else:\n                print(\"Retrying batch...\")\n                return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            return parsed\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying batch...\")\n            return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            raise e","prompt":"/system \n\nあなたはプロの翻訳者です。\n日本語で書かれた単語と文章のリストを受け取ります。\n同じリストを同じ順番で、{language}に翻訳して返してください。\n元のリストと同じ長さの文字列の有効なJSONリストを返すようにしてください。"}},{"step":"aggregation","completed":"2024-07-04T17:43:00.215064","duration":0.058654,"params":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"translations\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) \u003e 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"}},{"step":"visualization","completed":"2024-07-04T17:43:06.718003","duration":6.501127,"params":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"}}],"end_time":"2024-07-05T16:44:04.823174"},"extraction":{"limit":1000,"workers":1,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []\n","prompt":"/system\n\n\nあなたはプロのリサーチ・アシスタントで、私の仕事を手伝うことです。\n私の仕事は、論点を整理したきれいなデータセットを作成することです。\n\n背景は、私の上司が日本の都知事選挙に立候補したということです。\nこれから、出馬に関しての記事に一般から寄せられたコメントの例を挙げます。\nより簡潔で読みやすいものにするのを手伝ってほしい。\n本当に必要な場合は、2つの別々の議論に分けることもできるが、1つの議論を返すのが最善であることが多いだろう。\n\n結果は、きちんとフォーマットされた文字列形式（strings）のJSONリストとして返してください。\n\n\n/human\n\nAI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\n\n/ai \n\n[\n  \"私たちは、AI技術が環境に与える影響の軽減に焦点を当てるべきである\"\n]\n\n/human \n\nAIの能力、限界、倫理的配慮について一般の人々を教育するための協調的な努力が必要である。\n\n/ai \n\n[\n  \"AIの能力について一般の人々を教育すべきである。\",\n  \"AIの限界と倫理的配慮について、一般の人々を教育すべきである。\"\n]\n\n/human \n\nAIは、エネルギー効率と居住者のウェルビーイングのためにスマートホームやビルを最適化することができる。\n\n/ ai \n\n[\n  \"AIは、エネルギー効率と居住者のウェルビーイングのためにスマートホームやビルを最適化することができる。\"\n]\n\n/human \n\nAIはエネルギー・グリッドを最適化し、無駄と二酸化炭素排出を削減するのに役立つ。\n\n/ai \n\n[\n  \"AIはエネルギー網を最適化し、無駄と二酸化炭素排出を削減することができる。\"\n]\n","model":"gpt-4o"},"embedding":{"source_code":"\nfrom langchain.embeddings import OpenAIEmbeddings\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"},"clustering":{"clusters":8,"source_code":"\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4.\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom importlib import import_module\n\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # (!) we import the following modules dynamically for a reason\n    # (they are slow to load and not required for all pipelines)\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    stopwords = import_module('nltk.corpus').stopwords\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module(\n        'sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    stop = stopwords.words(\"english\")\n    vectorizer_model = CountVectorizer(stop_words=stop)\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # Fit the topic model.\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,  # Use the modified n_neighbors\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result\n"},"labelling":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nあなたは、より広範なコンサルテーション内の一連の議論に対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。あなたには、相談の主な質問、クラスタ内の議論のリスト、およびこのクラスタ外の議論のリストが与えられます。あなたはクラスターを要約する1つのカテゴリーラベルで回答します。\nラベルは非常に簡潔でなければならず、クラスターとその外側にある論点を区別するのに十分な正確さでなければならない。\n\n/human\n\nコンサルテーションの質問 「英国のEU離脱決定の影響は何だと思いますか？\n\n関心のあるクラスター以外の論点の例\n\n * エラスムス・プログラムからの除外により、教育・文化交流の機会が制限された。\n * 英国は、国境検問の強化による旅行時間の延長に対処し、通勤客や旅行客に影響を与えた。\n * 環境基準における協力が減少し、気候変動と闘う努力が妨げられた。\n * 相互医療協定の中断により、患者ケアに課題を感じた。\n * Brexit関連の変更により、家族の居住権や市民権の申請が複雑になった。\n * 英国は、共同研究機会の減少により、研究の課題に取り組む世界的な取り組みに支障をきたすことを目の当たりにした。\n * EUの文化助成プログラムからの除外により、創造的なプロジェクトの制限に直面した。\n * 英国は、EUの資金提供の喪失により、慈善活動やコミュニティ支援の後退を目の当たりにした。\n * 消費者保護の弱体化により、国境を越えた紛争解決に課題が生じた。\n * 英国はプロの音楽家としてEU諸国をツアーする際の制限に直面し、キャリアに影響を与えた。\n\nクラスター内部での議論の例\n\n * Brexitによりサプライチェーンが混乱し、企業にとってコスト増と納期遅延につながった。\n * ブレグジットのため、市場の変動や投資・退職金の不確実性に直面した。\n * 新たな関税や通関手続きにより、英国は輸出業者として利益率の低下に対処した。\n * ブレグジット後、企業がEU市場内にとどまるために事業を移転したため、雇用を失った。\n * 英国は輸入品価格の高騰による生活費の増加に苦しんだ。\n * 英国のハイテク産業への投資が減少し、技術革新と雇用機会に影響を与えた。\n * 新たなビザ規制による観光客の減少を目の当たりにし、接客業に影響。\n * ポンド価値の下落により購買力が低下し、旅費が増加した。\n\n\n/ai \n\n財務上のマイナス影響","model":"gpt-4o"},"takeaways":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたは、公開協議の際に参加者の一団から出された議論のリストを渡されます。あなたは、主な論点を1～2段落にまとめて回答します。あなたはとても簡潔で、読みやすい短い文章を書くことができます。\n \n/human\n\n[\n  \"銃による暴力は、私たちの社会における深刻な公衆衛生の危機を構成していると固く信じています。\",\n  \"包括的な銃規制策を通じて、この問題に早急に取り組む必要がある。\",\n  \"すべての銃購入者に対する身元調査の実施を支持します。\",\n  \"アサルト・ウェポンと大容量弾倉の禁止に賛成します。\",\n  \"違法な銃の売買を防ぐため、より厳しい規制を提唱します。\",\n  \"銃の購入プロセスにおいて、精神鑑定を義務付けるべきである。\"\n]\n\n/ai \n\n参加者は、包括的な銃規制を求め、普遍的な身元調査、突撃兵器の禁止、違法な銃売買の抑制、精神衛生評価の優先などを強調した。","model":"gpt-4o"},"overview":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)\n","prompt":"/system \n\nあなたはシンクタンクで働く専門家リサーチアシスタントです。\nあなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。\nあなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。\nあなたの仕事は、その結果を簡潔にまとめることです。\nあなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。","model":"gpt-4o"},"aggregation":{"source_code":"\"\"\"Generate a convenient JSON output file.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nimport json\n\n\ndef aggregation(config):\n\n    path = f\"outputs/{config['output_dir']}/result.json\"\n\n    results = {\n        \"clusters\": [],\n        \"comments\": {},\n        \"translations\": {},\n        \"overview\": \"\",\n        \"config\": config,\n    }\n\n    arguments = pd.read_csv(f\"outputs/{config['output_dir']}/args.csv\")\n    arguments.set_index('arg-id', inplace=True)\n\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n    useful_comment_ids = set(arguments['comment-id'].values)\n    for _, row in comments.iterrows():\n        id = row['comment-id']\n        if id in useful_comment_ids:\n            res = {'comment': row['comment-body']}\n            numeric_cols = ['agrees', 'disagrees']\n            string_cols = ['video', 'interview', 'timestamp']\n            for col in numeric_cols:\n                if col in row:\n                    res[col] = float(row[col])\n            for col in string_cols:\n                if col in row:\n                    res[col] = row[col]\n            results['comments'][str(id)] = res\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) \u003e 0:\n        with open(f\"outputs/{config['output_dir']}/translations.json\") as f:\n            translations = f.read()\n        results['translations'] = json.loads(translations)\n\n    clusters = pd.read_csv(f\"outputs/{config['output_dir']}/clusters.csv\")\n    labels = pd.read_csv(f\"outputs/{config['output_dir']}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{config['output_dir']}/takeaways.csv\")\n    takeaways.set_index('cluster-id', inplace=True)\n\n    with open(f\"outputs/{config['output_dir']}/overview.txt\") as f:\n        overview = f.read()\n    results['overview'] = overview\n\n    for _, row in labels.iterrows():\n        cid = row['cluster-id']\n        label = row['label']\n        arg_rows = clusters[clusters['cluster-id'] == cid]\n        arguments_in_cluster = []\n        for _, arg_row in arg_rows.iterrows():\n            arg_id = arg_row['arg-id']\n            argument = arguments.loc[arg_id]['argument']\n            comment_id = arguments.loc[arg_id]['comment-id']\n            x = float(arg_row['x'])\n            y = float(arg_row['y'])\n            p = float(arg_row['probability'])\n            obj = {\n                'arg_id': arg_id,\n                'argument': argument,\n                'comment_id': str(comment_id),\n                'x': x,\n                'y': y,\n                'p': p,\n            }\n            arguments_in_cluster.append(obj)\n        results['clusters'].append({\n            'cluster': label,\n            'cluster_id': str(cid),\n            'takeaways': takeaways.loc[cid]['takeaways'],\n            'arguments': arguments_in_cluster\n        })\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n"},"visualization":{"replacements":[],"source_code":"\nimport subprocess\n\n\ndef visualization(config):\n    output_dir = config['output_dir']\n    with open(f\"outputs/{output_dir}/result.json\") as f:\n        result = f.read()\n\n    cwd = \"../next-app\"\n    command = f\"REPORT={output_dir} npm run build\"\n\n    try:\n        process = subprocess.Popen(command, shell=True, cwd=cwd, stdout=subprocess.PIPE,\n                                   stderr=subprocess.PIPE, universal_newlines=True)\n        while True:\n            output_line = process.stdout.readline()\n            if output_line == '' and process.poll() is not None:\n                break\n            if output_line:\n                print(output_line.strip())\n        process.wait()\n        errors = process.stderr.read()\n        if errors:\n            print(\"Errors:\")\n            print(errors)\n    except subprocess.CalledProcessError as e:\n        print(\"Error: \", e)\n"},"plan":[{"step":"extraction","run":true,"reason":"some parameters changed: limit"},{"step":"embedding","run":true,"reason":"some dependent steps will re-run: extraction"},{"step":"clustering","run":true,"reason":"some dependent steps will re-run: embedding"},{"step":"labelling","run":true,"reason":"some dependent steps will re-run: clustering"},{"step":"takeaways","run":true,"reason":"some dependent steps will re-run: clustering"},{"step":"overview","run":true,"reason":"some dependent steps will re-run: labelling, takeaways"},{"step":"translation","run":true,"reason":"some dependent steps will re-run: extraction, labelling, takeaways, overview"},{"step":"aggregation","run":true,"reason":"some dependent steps will re-run: extraction, clustering, labelling, takeaways, overview, translation"},{"step":"visualization","run":true,"reason":"previous data not found"}],"status":"running","start_time":"2024-09-05T10:52:37.791951","completed_jobs":[{"step":"extraction","completed":"2024-09-05T10:57:12.750927","duration":274.95502,"params":{"limit":1000,"workers":1,"source_code":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\nimport concurrent.futures\n\n\ndef extraction(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/args.csv\"\n    comments = pd.read_csv(f\"inputs/{config['input']}.csv\")\n\n    model = config['extraction']['model']\n    prompt = config['extraction']['prompt']\n    workers = config['extraction']['workers']\n    limit = config['extraction']['limit']\n\n    comment_ids = (comments['comment-id'].values)[:limit]\n    comments.set_index('comment-id', inplace=True)\n    results = pd.DataFrame()\n    update_progress(config, total=len(comment_ids))\n    for i in tqdm(range(0, len(comment_ids), workers)):\n        batch = comment_ids[i: i + workers]\n        batch_inputs = [comments.loc[id]['comment-body'] for id in batch]\n        batch_results = extract_batch(batch_inputs, prompt, model, workers)\n        for comment_id, extracted_args in zip(batch, batch_results):\n            for j, arg in enumerate(extracted_args):\n                new_row = {\"arg-id\": f\"A{comment_id}_{j}\",\n                           \"comment-id\": int(comment_id), \"argument\": arg}\n                results = pd.concat(\n                    [results, pd.DataFrame([new_row])], ignore_index=True)\n        update_progress(config, incr=len(batch))\n    results.to_csv(path, index=False)\n\n\ndef extract_batch(batch, prompt, model, workers):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [executor.submit(\n            extract_arguments, input, prompt, model) for input in list(batch)]\n        concurrent.futures.wait(futures)\n        return [future.result() for future in futures]\n\n\ndef extract_arguments(input, prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    try:\n        obj = json.loads(response)\n        # LLM sometimes returns valid JSON string\n        if isinstance(obj, str):\n            obj = [obj]\n        items = [a.strip() for a in obj]\n        items = filter(None, items)  # omit empty strings\n        return items\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Input was:\", input)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying...\")\n            return extract_arguments(input, prompt, model, retries - 1)\n        else:\n            print(\"Silently giving up on trying to generate valid list.\")\n            return []\n","prompt":"/system\n\n\nあなたはプロのリサーチ・アシスタントで、私の仕事を手伝うことです。\n私の仕事は、論点を整理したきれいなデータセットを作成することです。\n\n背景は、私の上司が日本の都知事選挙に立候補したということです。\nこれから、出馬に関しての記事に一般から寄せられたコメントの例を挙げます。\nより簡潔で読みやすいものにするのを手伝ってほしい。\n本当に必要な場合は、2つの別々の議論に分けることもできるが、1つの議論を返すのが最善であることが多いだろう。\n\n結果は、きちんとフォーマットされた文字列形式（strings）のJSONリストとして返してください。\n\n\n/human\n\nAI技術は、そのライフサイクルにおける環境負荷の低減に重点を置いて開発されるべきである。\n\n/ai \n\n[\n  \"私たちは、AI技術が環境に与える影響の軽減に焦点を当てるべきである\"\n]\n\n/human \n\nAIの能力、限界、倫理的配慮について一般の人々を教育するための協調的な努力が必要である。\n\n/ai \n\n[\n  \"AIの能力について一般の人々を教育すべきである。\",\n  \"AIの限界と倫理的配慮について、一般の人々を教育すべきである。\"\n]\n\n/human \n\nAIは、エネルギー効率と居住者のウェルビーイングのためにスマートホームやビルを最適化することができる。\n\n/ ai \n\n[\n  \"AIは、エネルギー効率と居住者のウェルビーイングのためにスマートホームやビルを最適化することができる。\"\n]\n\n/human \n\nAIはエネルギー・グリッドを最適化し、無駄と二酸化炭素排出を削減するのに役立つ。\n\n/ai \n\n[\n  \"AIはエネルギー網を最適化し、無駄と二酸化炭素排出を削減することができる。\"\n]\n","model":"gpt-4o"}},{"step":"embedding","completed":"2024-09-05T10:57:14.857046","duration":2.104844,"params":{"source_code":"\nfrom langchain.embeddings import OpenAIEmbeddings\nimport pandas as pd\nfrom tqdm import tqdm\n\n\ndef embedding(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/embeddings.pkl\"\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    embeddings = []\n    for i in tqdm(range(0, len(arguments), 1000)):\n        args = arguments[\"argument\"].tolist()[i: i + 1000]\n        embeds = OpenAIEmbeddings().embed_documents(args)\n        embeddings.extend(embeds)\n    df = pd.DataFrame(\n        [\n            {\"arg-id\": arguments.iloc[i][\"arg-id\"], \"embedding\": e}\n            for i, e in enumerate(embeddings)\n        ]\n    )\n    df.to_pickle(path)\n"}},{"step":"clustering","completed":"2024-09-05T10:57:23.820604","duration":8.962923,"params":{"clusters":8,"source_code":"\"\"\"Cluster the arguments using UMAP + HDBSCAN and GPT-4.\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom importlib import import_module\n\n\ndef clustering(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/clusters.csv\"\n    arguments_df = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    arguments_array = arguments_df[\"argument\"].values\n\n    embeddings_df = pd.read_pickle(f\"outputs/{dataset}/embeddings.pkl\")\n    embeddings_array = np.asarray(embeddings_df[\"embedding\"].values.tolist())\n    clusters = config['clustering']['clusters']\n\n    result = cluster_embeddings(\n        docs=arguments_array,\n        embeddings=embeddings_array,\n        metadatas={\n            \"arg-id\": arguments_df[\"arg-id\"].values,\n            \"comment-id\": arguments_df[\"comment-id\"].values,\n        },\n        n_topics=clusters,\n    )\n    result.to_csv(path, index=False)\n\n\ndef cluster_embeddings(\n    docs,\n    embeddings,\n    metadatas,\n    min_cluster_size=2,\n    n_components=2,\n    n_topics=6,\n):\n    # (!) we import the following modules dynamically for a reason\n    # (they are slow to load and not required for all pipelines)\n    SpectralClustering = import_module('sklearn.cluster').SpectralClustering\n    stopwords = import_module('nltk.corpus').stopwords\n    HDBSCAN = import_module('hdbscan').HDBSCAN\n    UMAP = import_module('umap').UMAP\n    CountVectorizer = import_module(\n        'sklearn.feature_extraction.text').CountVectorizer\n    BERTopic = import_module('bertopic').BERTopic\n\n    umap_model = UMAP(\n        random_state=42,\n        n_components=n_components,\n    )\n    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size)\n\n    stop = stopwords.words(\"english\")\n    vectorizer_model = CountVectorizer(stop_words=stop)\n    topic_model = BERTopic(\n        umap_model=umap_model,\n        hdbscan_model=hdbscan_model,\n        vectorizer_model=vectorizer_model,\n        verbose=True,\n    )\n\n    # Fit the topic model.\n    _, __ = topic_model.fit_transform(docs, embeddings=embeddings)\n\n    n_samples = len(embeddings)\n    n_neighbors = min(n_samples - 1, 10)\n    spectral_model = SpectralClustering(\n        n_clusters=n_topics,\n        affinity=\"nearest_neighbors\",\n        n_neighbors=n_neighbors,  # Use the modified n_neighbors\n        random_state=42\n    )\n    umap_embeds = umap_model.fit_transform(embeddings)\n    cluster_labels = spectral_model.fit_predict(umap_embeds)\n\n    result = topic_model.get_document_info(\n        docs=docs,\n        metadata={\n            **metadatas,\n            \"x\": umap_embeds[:, 0],\n            \"y\": umap_embeds[:, 1],\n        },\n    )\n\n    result.columns = [c.lower() for c in result.columns]\n    result = result[['arg-id', 'x', 'y', 'probability']]\n    result['cluster-id'] = cluster_labels\n\n    return result\n"}},{"step":"labelling","completed":"2024-09-05T10:57:49.836055","duration":26.014046,"params":{"sample_size":30,"source_code":"\"\"\"Create labels for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef labelling(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/labels.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['labelling']['sample_size']\n    prompt = config['labelling']['prompt']\n    model = config['labelling']['model']\n\n    question = config['question']\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n\n        args_ids_outside = clusters[clusters['cluster-id']\n                                    != cluster_id]['arg-id'].values\n        args_ids_outside = np.random.choice(args_ids_outside, size=min(\n            len(args_ids_outside), sample_size), replace=False)\n        args_sample_outside = arguments[arguments['arg-id']\n                                        .isin(args_ids_outside)]['argument'].values\n\n        label = generate_label(question, args_sample,\n                               args_sample_outside, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'label': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_label(question, args_sample, args_sample_outside, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    outside = '\\n * ' + '\\n * '.join(args_sample_outside)\n    inside = '\\n * ' + '\\n * '.join(args_sample)\n    input = f\"Question of the consultation:{question}\\n\\n\" + \\\n        f\"Examples of arguments OUTSIDE the cluster:\\n {outside}\" + \\\n        f\"Examples of arguments INSIDE the cluster:\\n {inside}\"\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nあなたは、より広範なコンサルテーション内の一連の議論に対するカテゴリラベルを生成するカテゴリラベリングアシスタントです。あなたには、相談の主な質問、クラスタ内の議論のリスト、およびこのクラスタ外の議論のリストが与えられます。あなたはクラスターを要約する1つのカテゴリーラベルで回答します。\nラベルは非常に簡潔でなければならず、クラスターとその外側にある論点を区別するのに十分な正確さでなければならない。\n\n/human\n\nコンサルテーションの質問 「英国のEU離脱決定の影響は何だと思いますか？\n\n関心のあるクラスター以外の論点の例\n\n * エラスムス・プログラムからの除外により、教育・文化交流の機会が制限された。\n * 英国は、国境検問の強化による旅行時間の延長に対処し、通勤客や旅行客に影響を与えた。\n * 環境基準における協力が減少し、気候変動と闘う努力が妨げられた。\n * 相互医療協定の中断により、患者ケアに課題を感じた。\n * Brexit関連の変更により、家族の居住権や市民権の申請が複雑になった。\n * 英国は、共同研究機会の減少により、研究の課題に取り組む世界的な取り組みに支障をきたすことを目の当たりにした。\n * EUの文化助成プログラムからの除外により、創造的なプロジェクトの制限に直面した。\n * 英国は、EUの資金提供の喪失により、慈善活動やコミュニティ支援の後退を目の当たりにした。\n * 消費者保護の弱体化により、国境を越えた紛争解決に課題が生じた。\n * 英国はプロの音楽家としてEU諸国をツアーする際の制限に直面し、キャリアに影響を与えた。\n\nクラスター内部での議論の例\n\n * Brexitによりサプライチェーンが混乱し、企業にとってコスト増と納期遅延につながった。\n * ブレグジットのため、市場の変動や投資・退職金の不確実性に直面した。\n * 新たな関税や通関手続きにより、英国は輸出業者として利益率の低下に対処した。\n * ブレグジット後、企業がEU市場内にとどまるために事業を移転したため、雇用を失った。\n * 英国は輸入品価格の高騰による生活費の増加に苦しんだ。\n * 英国のハイテク産業への投資が減少し、技術革新と雇用機会に影響を与えた。\n * 新たなビザ規制による観光客の減少を目の当たりにし、接客業に影響。\n * ポンド価値の下落により購買力が低下し、旅費が増加した。\n\n\n/ai \n\n財務上のマイナス影響","model":"gpt-4o"}},{"step":"takeaways","completed":"2024-09-05T10:58:11.949286","duration":22.111757,"params":{"sample_size":30,"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef takeaways(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/takeaways.csv\"\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    clusters = pd.read_csv(f\"outputs/{dataset}/clusters.csv\")\n\n    results = pd.DataFrame()\n\n    sample_size = config['takeaways']['sample_size']\n    prompt = config['takeaways']['prompt']\n    model = config['takeaways']['model']\n\n    model = config.get('model_takeaways', config.get('model', 'gpt3.5-turbo'))\n    cluster_ids = clusters['cluster-id'].unique()\n\n    update_progress(config, total=len(cluster_ids))\n\n    for _, cluster_id in tqdm(enumerate(cluster_ids), total=len(cluster_ids)):\n        args_ids = clusters[clusters['cluster-id']\n                            == cluster_id]['arg-id'].values\n        args_ids = np.random.choice(args_ids, size=min(\n            len(args_ids), sample_size), replace=False)\n        args_sample = arguments[arguments['arg-id']\n                                .isin(args_ids)]['argument'].values\n        label = generate_takeaways(args_sample, prompt, model)\n        results = pd.concat([results, pd.DataFrame(\n            [{'cluster-id': cluster_id, 'takeaways': label}])], ignore_index=True)\n        update_progress(config, incr=1)\n\n    results.to_csv(path, index=False)\n\n\ndef generate_takeaways(args_sample, prompt, model):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = \"\\n\".join(args_sample)\n    response = llm(messages=messages(prompt, input)).content.strip()\n    return response\n","prompt":"/system \n\nあなたはシンクタンクで働く専門家リサーチアシスタントです。あなたは、公開協議の際に参加者の一団から出された議論のリストを渡されます。あなたは、主な論点を1～2段落にまとめて回答します。あなたはとても簡潔で、読みやすい短い文章を書くことができます。\n \n/human\n\n[\n  \"銃による暴力は、私たちの社会における深刻な公衆衛生の危機を構成していると固く信じています。\",\n  \"包括的な銃規制策を通じて、この問題に早急に取り組む必要がある。\",\n  \"すべての銃購入者に対する身元調査の実施を支持します。\",\n  \"アサルト・ウェポンと大容量弾倉の禁止に賛成します。\",\n  \"違法な銃の売買を防ぐため、より厳しい規制を提唱します。\",\n  \"銃の購入プロセスにおいて、精神鑑定を義務付けるべきである。\"\n]\n\n/ai \n\n参加者は、包括的な銃規制を求め、普遍的な身元調査、突撃兵器の禁止、違法な銃売買の抑制、精神衛生評価の優先などを強調した。","model":"gpt-4o"}},{"step":"overview","completed":"2024-09-05T10:58:17.862910","duration":5.910473,"params":{"source_code":"\"\"\"Create summaries for the clusters.\"\"\"\n\nfrom tqdm import tqdm\nimport os\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, update_progress\n\n\ndef overview(config):\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/overview.txt\"\n\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n\n    prompt = config['overview']['prompt']\n    model = config['overview']['model']\n\n    ids = labels['cluster-id'].to_list()\n    takeaways.set_index('cluster-id', inplace=True)\n    labels.set_index('cluster-id', inplace=True)\n\n    input = ''\n    for i, id in enumerate(ids):\n        input += f\"# Cluster {i}/{len(ids)}: {labels.loc[id]['label']}\\n\\n\"\n        input += takeaways.loc[id]['takeaways'] + '\\n\\n'\n\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    response = llm(messages=messages(prompt, input)).content.strip()\n\n    with open(path, 'w') as file:\n        file.write(response)\n","prompt":"/system \n\nあなたはシンクタンクで働く専門家リサーチアシスタントです。\nあなたのチームは、あるトピックに関する公開コンサルテーションを実施し、さまざまな選択肢のクラスターを分析し始めました。\nあなたは今、クラスターのリストと各クラスターの簡単な分析を受け取ります。\nあなたの仕事は、その結果を簡潔にまとめることです。\nあなたの要約は非常に簡潔でなければならず（せいぜい1段落、せいぜい4文）、平凡な表現は避けなければなりません。","model":"gpt-4o"}},{"step":"translation","completed":"2024-09-05T10:58:17.870809","duration":0.00269,"params":{"model":"gpt-4","languages":[],"flags":[],"source_code":"import json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom langchain.chat_models import ChatOpenAI\nfrom utils import messages, t\nfrom langchain.schema import AIMessage\nimport pandas as pd\nimport json\nfrom tqdm import tqdm\n\ndef translation(config):\n\n    dataset = config['output_dir']\n    path = f\"outputs/{dataset}/translations.json\"\n    results = {}\n\n    languages = list(config.get('translation', {}).get('languages', []))\n    if len(languages) == 0:\n        print(\"No languages specified. Skipping translation step.\")\n        # creating an empty file any, to reduce special casing later\n        with open(path, 'w') as file:\n            json.dump(results, file, indent=2)\n        return\n\n    arguments = pd.read_csv(f\"outputs/{dataset}/args.csv\")\n    labels = pd.read_csv(f\"outputs/{dataset}/labels.csv\")\n    takeaways = pd.read_csv(f\"outputs/{dataset}/takeaways.csv\")\n    with open(f\"outputs/{dataset}/overview.txt\") as f:\n        overview = f.read()\n\n    UI_copy = [t(\"Argument\"), t(\"Original comment\"), t(\"Representative arguments\"),\n               t(\"Open full-screen map\"), t(\"Back to report\"), t(\"Hide labels\"), t(\"Show labels\"),\n               t(\"Show filters\"), t(\"Hide filters\"), t(\"Min. votes\"), t(\"Consensus\"),\n               t(\"Showing\"), t(\"arguments\"), t(\"Reset zoom\"), t(\"Click anywhere on the map to close this\"),\n               t(\"Click on the dot for details\"), t(\"agree\"), t(\"disagree\"), t(\"Language\"),\n               t(\"English\"), t(\"arguments\"), t(\"of total\"), t(\"Overview\"), t(\"Cluster analysis\"),\n               t(\"Representative comments\"), t(\"Introduction\"), t(\"Clusters\"), t(\"Appendix\"),\n               t(\"This report was generated using an AI pipeline that consists of the following steps\"),\n               t(\"Step\"), t(\"extraction\"), t(\"show code\"), t(\"hide code\"), t(\"show prompt\"),\n               t(\"hide prompt\"), t(\"embedding\"), t(\"clustering\"), t(\"labelling\"), t(\"takeaways\"),\n               t(\"overview\")]\n\n    arg_list = arguments['argument'].to_list() + \\\n        labels['label'].to_list() + \\\n        UI_copy + \\\n        languages\n\n    if 'name' in config:\n        arg_list.append(config['name'])\n    if 'question' in config:\n        arg_list.append(config['question'])\n\n    prompt_file = config.get('translation_prompt', 'default')\n    with open(f\"prompts/translation/{prompt_file}.txt\") as f:\n        prompt = f.read()\n    model = config['model']\n\n    config['translation_prompt'] = prompt\n\n    translations = [translate_lang(\n        arg_list, 10, prompt, lang, model) for lang in languages]\n\n    # handling long takeaways differently, WITHOUT batching too much\n    long_arg_list = takeaways['takeaways'].to_list()\n    long_arg_list.append(overview)\n    if 'intro' in config:\n        long_arg_list.append(config['intro'])\n\n    long_translations = [translate_lang(\n        long_arg_list, 1, prompt, lang, model) for lang in languages]\n\n    for i, id in enumerate(arg_list):\n        print('i, id', i, id)\n        results[str(id)] = list([t[i] for t in translations])\n    for i, id in enumerate(long_arg_list):\n        results[str(id)] = list([t[i] for t in long_translations])\n\n    with open(path, 'w') as file:\n        json.dump(results, file, indent=2)\n\n\ndef translate_lang(arg_list, batch_size, prompt, lang, model):\n    translations = []\n    lang_prompt = prompt.replace(\"{language}\", lang)\n    print(f\"Translating to {lang}...\")\n    for i in tqdm(range(0, len(arg_list), batch_size)):\n        batch = arg_list[i: i + batch_size]\n        translations.extend(translate_batch(batch, lang_prompt, model))\n    return translations\n\n\ndef translate_batch(batch, lang_prompt, model, retries=3):\n    llm = ChatOpenAI(model_name=model, temperature=0.0)\n    input = json.dumps(list(batch))\n    response = llm(messages=messages(lang_prompt, input)).content.strip()\n    if \"```\" in response:\n        response = response.split(\"```\")[1]\n    if response.startswith(\"json\"):\n        response = response[4:]\n    try:\n        parsed = [a.strip() for a in json.loads(response)]\n        if len(parsed) != len(batch):\n            print(\"Warning: batch size mismatch!\")\n            print(\"Batch len:\", len(batch))\n            print(\"Response len:\", len(parsed))\n            for i, item in enumerate(batch):\n                print(f\"Batch item {i}:\", item)\n                if (i \u003c len(parsed)):\n                    print(\"Response:\", parsed[i])\n            if (len(batch) \u003e 1):\n                print(\"Retrying with smaller batches...\")\n                mid = len(batch) // 2\n                return translate_batch(batch[:mid], lang_prompt, model, retries - 1) + \\\n                    translate_batch(\n                        batch[mid:], lang_prompt, model, retries - 1)\n            else:\n                print(\"Retrying batch...\")\n                return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            return parsed\n    except json.decoder.JSONDecodeError as e:\n        print(\"JSON error:\", e)\n        print(\"Response was:\", response)\n        if retries \u003e 0:\n            print(\"Retrying batch...\")\n            return translate_batch(batch, lang_prompt, model, retries - 1)\n        else:\n            raise e","prompt":"/system \n\nあなたはプロの翻訳者です。\n日本語で書かれた単語と文章のリストを受け取ります。\n同じリストを同じ順番で、{language}に翻訳して返してください。\n元のリストと同じ長さの文字列の有効なJSONリストを返すようにしてください。"}}],"lock_until":"2024-09-05T11:03:17.872739","current_job":"aggregation","current_job_started":"2024-09-05T10:58:17.872727"}}},"__N_SSG":true},"page":"/","query":{},"buildId":"fW86tV8TMvqC8n4utOYdy","assetPrefix":".","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>